{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "010ffa2f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-22T17:51:58.891279Z",
     "iopub.status.busy": "2023-03-22T17:51:58.890703Z",
     "iopub.status.idle": "2023-03-22T17:51:58.906417Z",
     "shell.execute_reply": "2023-03-22T17:51:58.905263Z"
    },
    "papermill": {
     "duration": 0.027502,
     "end_time": "2023-03-22T17:51:58.909206",
     "exception": false,
     "start_time": "2023-03-22T17:51:58.881704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/2023-nlp-lab1-problem1/submission_example.csv\n",
      "/kaggle/input/2023-nlp-lab1-problem1/simple_seq.train.csv\n",
      "/kaggle/input/2023-nlp-lab1-problem1/simple_seq.test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5345506e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T17:51:58.922675Z",
     "iopub.status.busy": "2023-03-22T17:51:58.922057Z",
     "iopub.status.idle": "2023-03-22T17:52:06.782021Z",
     "shell.execute_reply": "2023-03-22T17:52:06.780863Z"
    },
    "papermill": {
     "duration": 7.869582,
     "end_time": "2023-03-22T17:52:06.784672",
     "exception": false,
     "start_time": "2023-03-22T17:51:58.915090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W25 W26 W27 W19 W28 W29 W30 W31 W32 W33 W34 W35 W36 W37 W38 W39 W24 W40 D11',\n",
       " 'W41 W4 W42 W43 W44 W45 W46 W47 W48 W49 W50 W51 W52 W53 W17 W54 W24 D1',\n",
       " 'W55 W19 W46 W32 W32 W56 W57 W58 W59 W19 W13 W60 W19 W13 W61 W62 D3',\n",
       " 'W13 W83 W32 W32 W56 W57 W13 W84 W19 W28 W85 W86 W24 D20',\n",
       " 'W87 W88 W89 W90 W32 W91 W13 W92 W93 W90 W94 W95 W24 D20',\n",
       " 'W13 W52 W32 W53 W17 W13 W96 W97 W10 W2 W98 W99 W19 W13 W100 W24 D20',\n",
       " 'W122 W123 W110 W124 W125 W19 W13 W126 W127 W128 W32 W129 W130 W36 W13 W131 W132 W17 W133 W24 D20',\n",
       " 'W1 W2 W3 W4 W134 W7 W28 W78 W19 W13 W135 W136 W137 W138 W139 W90 W17 W140 W24 D1',\n",
       " 'W154 W155 W134 W47 W139 W28 W156 W157 W97 W90 W158 W159 W46 W32 W154 W46 W160 W161 W24 D20',\n",
       " 'W17 W162 W12 W163 W144 W12 W55 W164 W165 W32 W166 W167 W46 W168 W32 W169 W24 D20']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, LSTM, Bidirectional, CuDNNGRU, Activation, CuDNNLSTM \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.metrics import MeanSquaredError\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_squared_log_error, r2_score\n",
    "#from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dropout\n",
    "from scipy import interpolate\n",
    "from scipy import stats\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.initializers import GlorotUniform\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with open(\"/kaggle/input/2023-nlp-lab1-problem1/simple_seq.train.csv\") as f:\n",
    "    lines = f.read() ##Assume the sample file has 3 lines\n",
    "    lines = \"\".join([s for s in lines.strip().splitlines(True) if s.strip()])\n",
    "    first = lines.split('\\n', -1)\n",
    "    train_list = []\n",
    "    for i in range(len(first)):\n",
    "        strings = first[i].replace(\" \",\"\")\n",
    "        strings = first[i].split(',', -1)\n",
    "        strings = [v for v in strings if v]         # 빈요소 \"\" 제거 \n",
    "        strings = \" \".join(strings)\n",
    "        train_list.append(strings)\n",
    "        \n",
    "        \n",
    "train_list[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b6882c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T17:52:06.798766Z",
     "iopub.status.busy": "2023-03-22T17:52:06.797634Z",
     "iopub.status.idle": "2023-03-22T17:52:06.807622Z",
     "shell.execute_reply": "2023-03-22T17:52:06.806504Z"
    },
    "papermill": {
     "duration": 0.019461,
     "end_time": "2023-03-22T17:52:06.809976",
     "exception": false,
     "start_time": "2023-03-22T17:52:06.790515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12335"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = []       # train_words\n",
    "for s in train_list:     # 문장에서 단어 단위로 쪼개기 \n",
    "    words.extend(s.split())\n",
    "words[0:20]\n",
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a31cb25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T17:52:06.823471Z",
     "iopub.status.busy": "2023-03-22T17:52:06.823104Z",
     "iopub.status.idle": "2023-03-22T17:52:06.836989Z",
     "shell.execute_reply": "2023-03-22T17:52:06.835827Z"
    },
    "papermill": {
     "duration": 0.025429,
     "end_time": "2023-03-22T17:52:06.841301",
     "exception": false,
     "start_time": "2023-03-22T17:52:06.815872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[PAD]': 0, '[UNK]': 1, 'W25': 2, 'W26': 3, 'W27': 4, 'W19': 5, 'W28': 6, 'W29': 7, 'W30': 8, 'W31': 9, 'W32': 10, 'W33': 11, 'W34': 12, 'W35': 13, 'W36': 14, 'W37': 15, 'W38': 16, 'W39': 17, 'W24': 18, 'W40': 19, 'D11': 20, 'W41': 21, 'W4': 22, 'W42': 23, 'W43': 24, 'W44': 25, 'W45': 26, 'W46': 27, 'W47': 28, 'W48': 29, 'W49': 30, 'W50': 31, 'W51': 32, 'W52': 33, 'W53': 34, 'W17': 35, 'W54': 36, 'D1': 37, 'W55': 38, 'W56': 39, 'W57': 40, 'W58': 41, 'W59': 42, 'W13': 43, 'W60': 44, 'W61': 45, 'W62': 46, 'D3': 47, 'W83': 48, 'W84': 49, 'W85': 50, 'W86': 51, 'D20': 52, 'W87': 53, 'W88': 54, 'W89': 55, 'W90': 56, 'W91': 57, 'W92': 58, 'W93': 59, 'W94': 60, 'W95': 61, 'W96': 62, 'W97': 63, 'W10': 64, 'W2': 65, 'W98': 66, 'W99': 67, 'W100': 68, 'W122': 69, 'W123': 70, 'W110': 71, 'W124': 72, 'W125': 73, 'W126': 74, 'W127': 75, 'W128': 76, 'W129': 77, 'W130': 78, 'W131': 79, 'W132': 80, 'W133': 81, 'W1': 82, 'W3': 83, 'W134': 84, 'W7': 85, 'W78': 86, 'W135': 87, 'W136': 88, 'W137': 89, 'W138': 90, 'W139': 91, 'W140': 92, 'W154': 93, 'W155': 94, 'W156': 95, 'W157': 96, 'W158': 97, 'W159': 98, 'W160': 99, 'W161': 100, 'W162': 101, 'W12': 102, 'W163': 103, 'W144': 104, 'W164': 105, 'W165': 106, 'W166': 107, 'W167': 108, 'W168': 109, 'W169': 110, 'W201': 111, 'W202': 112, 'W203': 113, 'W204': 114, 'W205': 115, 'W206': 116, 'W8': 117, 'W207': 118, 'W208': 119, 'W209': 120, 'W210': 121, 'W211': 122, 'W212': 123, 'W213': 124, 'D12': 125, 'W214': 126, 'W215': 127, 'W216': 128, 'W217': 129, 'W218': 130, 'W219': 131, 'D15': 132, 'W21': 133, 'W220': 134, 'W221': 135, 'W222': 136, 'W223': 137, 'W224': 138, 'W225': 139, 'W226': 140, 'W227': 141, 'W228': 142, 'W229': 143, 'W230': 144, 'W142': 145, 'W231': 146, 'D4': 147, 'W279': 148, 'W280': 149, 'W281': 150, 'W282': 151, 'W271': 152, 'W283': 153, 'W284': 154, 'W285': 155, 'W286': 156, 'W287': 157, 'W288': 158, 'W289': 159, 'W290': 160, 'W291': 161, 'W292': 162, 'W293': 163, 'D5': 164, 'W296': 165, 'W303': 166, 'W304': 167, 'W305': 168, 'W64': 169, 'W306': 170, 'W307': 171, 'W308': 172, 'W309': 173, 'W310': 174, 'W311': 175, 'D16': 176, 'W328': 177, 'W261': 178, 'W262': 179, 'W329': 180, 'W255': 181, 'W330': 182, 'W331': 183, 'W274': 184, 'W332': 185, 'W333': 186, 'W334': 187, 'W335': 188, 'W336': 189, 'W337': 190, 'W338': 191, 'W339': 192, 'W340': 193, 'W341': 194, 'W342': 195, 'W343': 196, 'W344': 197, 'W345': 198, 'W346': 199, 'W112': 200, 'W113': 201, 'W347': 202, 'W348': 203, 'W349': 204, 'W350': 205, 'W351': 206, 'W183': 207, 'W364': 208, 'W365': 209, 'W366': 210, 'W367': 211, 'W368': 212, 'W363': 213, 'W357': 214, 'W369': 215, 'W370': 216, 'W371': 217, 'W372': 218, 'W373': 219, 'W374': 220, 'W117': 221, 'W375': 222, 'W376': 223, 'W377': 224, 'W378': 225, 'W379': 226, 'W380': 227, 'W149': 228, 'W391': 229, 'W392': 230, 'W393': 231, 'W389': 232, 'W394': 233, 'W403': 234, 'W404': 235, 'W405': 236, 'W406': 237, 'W407': 238, 'W408': 239, 'W409': 240, 'W462': 241, 'W463': 242, 'W246': 243, 'W464': 244, 'W465': 245, 'W466': 246, 'W467': 247, 'W398': 248, 'W534': 249, 'W503': 250, 'W535': 251, 'W536': 252, 'W115': 253, 'W401': 254, 'W582': 255, 'W354': 256, 'W583': 257, 'W584': 258, 'W585': 259, 'W586': 260, 'W587': 261, 'W443': 262, 'W588': 263, 'W589': 264, 'W433': 265, 'W638': 266, 'W642': 267, 'W657': 268, 'W658': 269, 'W659': 270, 'W660': 271, 'W434': 272, 'W661': 273, 'W662': 274, 'W663': 275, 'W664': 276, 'W495': 277, 'W665': 278, 'W475': 279, 'W528': 280, 'W457': 281, 'W666': 282, 'W654': 283, 'W667': 284, 'W692': 285, 'W698': 286, 'W411': 287, 'W755': 288, 'W756': 289, 'W795': 290, 'W787': 291, 'W796': 292, 'W797': 293, 'W798': 294, 'W799': 295, 'W626': 296, 'W800': 297, 'W801': 298, 'W802': 299, 'W803': 300, 'W694': 301, 'W804': 302, 'W805': 303, 'W806': 304, 'W807': 305, 'W300': 306, 'W808': 307, 'W809': 308, 'W647': 309, 'W498': 310, 'W69': 311, 'W835': 312, 'W555': 313, 'W836': 314, 'W114': 315, 'W468': 316, 'W837': 317, 'W851': 318, 'W321': 319, 'W852': 320, 'W853': 321, 'W854': 322, 'W855': 323, 'W680': 324, 'W856': 325, 'W461': 326, 'W844': 327, 'W111': 328, 'W863': 329, 'W516': 330, 'W864': 331, 'W170': 332, 'W865': 333, 'W188': 334, 'W866': 335, 'W867': 336, 'W550': 337, 'W640': 338, 'W879': 339, 'W533': 340, 'W893': 341, 'W894': 342, 'W636': 343, 'W895': 344, 'W896': 345, 'D28': 346, 'W918': 347, 'W919': 348, 'W920': 349, 'W925': 350, 'W934': 351, 'W935': 352, 'W936': 353, 'W937': 354, 'W152': 355, 'W597': 356, 'W938': 357, 'W970': 358, 'W971': 359, 'W940': 360, 'W746': 361, 'W972': 362, 'W430': 363, 'W646': 364, 'W967': 365, 'W973': 366, 'W974': 367, 'W975': 368, 'W68': 369, 'W574': 370, 'W245': 371, 'W976': 372, 'W977': 373, 'W963': 374, 'W978': 375, 'W66': 376, 'W790': 377, 'W979': 378, 'W980': 379, 'W981': 380, 'W926': 381, 'W119': 382, 'W908': 383, 'W1034': 384, 'W984': 385, 'W1014': 386, 'W1035': 387, 'W1036': 388, 'W1037': 389, 'W104': 390, 'W480': 391, 'W553': 392, 'W1072': 393, 'W1073': 394, 'W1074': 395, 'W1085': 396, 'W173': 397, 'W489': 398, 'W1086': 399, 'W252': 400, 'W1087': 401, 'W1088': 402, 'W1101': 403, 'W1102': 404, 'W1103': 405, 'W1104': 406, 'W1124': 407, 'W1125': 408, 'W1043': 409, 'W1126': 410, 'W1127': 411, 'W1128': 412, 'W1129': 413, 'W1010': 414, 'W1130': 415, 'W1131': 416, 'W928': 417, 'W1138': 418, 'W526': 419, 'W1139': 420, 'W1140': 421, 'W930': 422, 'W472': 423, 'W1141': 424, 'W539': 425, 'W1142': 426, 'W1143': 427, 'W1110': 428, 'W1146': 429, 'W15': 430, 'W1147': 431, 'W1148': 432, 'W1149': 433, 'W1150': 434, 'W1151': 435, 'W1152': 436, 'W1153': 437, 'W848': 438, 'W1177': 439, 'W1181': 440, 'W1160': 441, 'W1182': 442, 'W1183': 443, 'W1004': 444, 'W910': 445, 'W494': 446, 'W1041': 447, 'W1191': 448, 'W1192': 449, 'W923': 450, 'W1193': 451, 'W1194': 452, 'W187': 453, 'W950': 454, 'W1195': 455, 'W1196': 456, 'W1197': 457, 'W1198': 458, 'W1208': 459, 'W689': 460, 'W1209': 461, 'W235': 462, 'W1210': 463, 'W1211': 464, 'W324': 465, 'W929': 466, 'W1227': 467, 'W1165': 468, 'W1167': 469, 'W1228': 470, 'W904': 471, 'W1252': 472, 'W1253': 473, 'W1254': 474, 'W1255': 475, 'W1159': 476, 'W1256': 477, 'W70': 478, 'W1261': 479, 'W1262': 480, 'W1214': 481, 'W1263': 482, 'W993': 483, 'W1205': 484, 'W417': 485, 'W493': 486, 'W253': 487, 'W1271': 488, 'W184': 489, 'W1021': 490, 'W1272': 491, 'W951': 492, 'W1273': 493, 'W428': 494, 'W1274': 495, 'W580': 496, 'W1284': 497, 'W1204': 498, 'W1285': 499, 'W1200': 500, 'W387': 501, 'W1287': 502, 'W1174': 503, 'W627': 504, 'W385': 505, 'W1306': 506, 'W1307': 507, 'W1310': 508, 'W1311': 509, 'W1312': 510, 'W1075': 511, 'W1325': 512, 'W1305': 513, 'W1270': 514, 'W358': 515, 'W386': 516, 'W450': 517, 'W1371': 518, 'W1020': 519, 'W609': 520, 'W1118': 521, 'W1017': 522, 'W1032': 523, 'W1386': 524, 'W241': 525, 'W1387': 526, 'W5': 527, 'W1388': 528, 'W1389': 529, 'W1392': 530, 'W1393': 531, 'W1044': 532, 'W1096': 533, 'W1394': 534, 'W604': 535, 'W446': 536, 'W1395': 537, 'W1396': 538, 'W731': 539, 'W927': 540, 'W1397': 541, 'W1398': 542, 'W1399': 543, 'W1412': 544, 'W1413': 545, 'W1414': 546, 'W1003': 547, 'W577': 548, 'W1415': 549, 'W1162': 550, 'W1425': 551, 'W236': 552, 'W251': 553, 'W1426': 554, 'W540': 555, 'W1427': 556, 'W1029': 557, 'W429': 558, 'W1428': 559, 'W1439': 560, 'W1440': 561, 'W1338': 562, 'W1409': 563, 'W1460': 564, 'W1117': 565, 'W1461': 566, 'W1449': 567, 'W1462': 568, 'W1463': 569, 'W954': 570, 'W1467': 571, 'W1315': 572, 'W1473': 573, 'W1474': 574, 'W301': 575, 'W1475': 576, 'W1243': 577, 'W1487': 578, 'W1488': 579, 'W610': 580, 'W1506': 581, 'W1507': 582, 'W744': 583, 'W1508': 584, 'W1509': 585, 'W1510': 586, 'W1511': 587, 'W1538': 588, 'W1516': 589, 'W1517': 590, 'W1571': 591, 'W949': 592, 'W1586': 593, 'W1587': 594, 'W1573': 595, 'W512': 596, 'W1275': 597, 'W470': 598, 'W1627': 599, 'W426': 600, 'W1528': 601, 'W1512': 602, 'W1666': 603, 'W1667': 604, 'W1042': 605, 'W1563': 606, 'W1277': 607, 'W1011': 608, 'W983': 609, 'W1526': 610, 'W427': 611, 'W1677': 612, 'W1697': 613, 'W106': 614, 'W1698': 615, 'W1553': 616, 'W1796': 617, 'W312': 618, 'W532': 619, 'W1797': 620, 'W1798': 621, 'W314': 622, 'W932': 623, 'W1730': 624, 'W1731': 625, 'W1832': 626, 'W105': 627, 'W617': 628, 'W1264': 629, 'W1265': 630, 'W1810': 631, 'W1783': 632, 'W1784': 633, 'W641': 634, 'W1298': 635, 'W1960': 636, 'W595': 637, 'W901': 638, 'W1966': 639, 'W1058': 640, 'W1411': 641, 'W1982': 642, 'W1983': 643, 'W1984': 644, 'W1985': 645, 'W1986': 646, 'W1343': 647, 'W1987': 648, 'W1846': 649, 'W1988': 650, 'W1989': 651, 'W1990': 652, 'W1991': 653, 'W2004': 654, 'W748': 655, 'W2005': 656, 'W2006': 657, 'W2010': 658, 'W2009': 659, 'W1120': 660, 'W2011': 661, 'W2015': 662, 'W874': 663, 'W2016': 664, 'W242': 665, 'W1632': 666, 'W297': 667, 'W2024': 668, 'W2025': 669, 'W435': 670, 'W1976': 671, 'W323': 672, 'W2026': 673, 'W2027': 674, 'W2028': 675, 'W1757': 676, 'W2036': 677, 'W2037': 678, 'W1339': 679, 'W2038': 680, 'W889': 681, 'W2039': 682, 'W2040': 683, 'W778': 684, 'W2041': 685, 'W2042': 686, 'W397': 687, 'W2043': 688, 'W2044': 689, 'W146': 690, 'W931': 691, 'W946': 692, 'W2045': 693, 'W1115': 694, 'W2046': 695, 'W232': 696, 'W2047': 697, 'W2048': 698, 'W1372': 699, 'W1824': 700, 'W2049': 701, 'W2050': 702, 'W2051': 703, 'W1831': 704, 'W2052': 705, 'W2053': 706, 'W2054': 707, 'W2055': 708, 'W2059': 709, 'W2060': 710, 'W2066': 711, 'W1857': 712, 'W2067': 713, 'W2068': 714, 'W2077': 715, 'W2078': 716, 'W1296': 717, 'W2079': 718, 'W1965': 719, 'W575': 720, 'W2085': 721, 'W2086': 722, 'W2084': 723, 'D6': 724, 'W1503': 725, 'W2087': 726, 'W1248': 727, 'W2088': 728, 'W412': 729, 'W2089': 730, 'W1097': 731, 'W1090': 732, 'W840': 733, 'W264': 734, 'D17': 735, 'W875': 736, 'W76': 737, 'W2104': 738, 'W2105': 739, 'W2118': 740, 'W2130': 741, 'W2131': 742, 'W1083': 743, 'W1868': 744, 'W2132': 745, 'W2133': 746, 'W1144': 747, 'W2125': 748, 'W2135': 749, 'W2142': 750, 'W2143': 751, 'W505': 752, 'D19': 753, 'W2112': 754, 'W1776': 755, 'W2144': 756, 'W2145': 757, 'W1890': 758, 'W2146': 759, 'W2147': 760, 'W2148': 761, 'W2149': 762, 'W2150': 763, 'W1203': 764, 'W2151': 765, 'W515': 766, 'W259': 767, 'W2152': 768, 'W2153': 769, 'W1820': 770, 'W2154': 771, 'W2155': 772, 'W2156': 773, 'W1582': 774, 'W2157': 775, 'W2168': 776, 'W2167': 777, 'W1603': 778, 'W1383': 779, 'W180': 780, 'W2228': 781, 'W956': 782, 'W270': 783, 'W2229': 784, 'W2230': 785, 'W2218': 786, 'W559': 787, 'W2231': 788, 'W861': 789, 'W1781': 790, 'W507': 791, 'W1280': 792, 'W2242': 793, 'W2269': 794, 'W2270': 795, 'W1702': 796, 'W496': 797, 'W1368': 798, 'W383': 799, 'W437': 800, 'W2189': 801, 'W81': 802, 'W2271': 803, 'W764': 804, 'W244': 805, 'W2272': 806, 'W2273': 807, 'W1366': 808, 'W2303': 809, 'W2308': 810, 'W2192': 811, 'W2315': 812, 'W2320': 813, 'W1819': 814, 'W791': 815, 'W441': 816, 'W316': 817, 'W2309': 818, 'W2321': 819, 'W325': 820, 'W2328': 821, 'W1436': 822, 'W2336': 823, 'W1106': 824, 'W2337': 825, 'W707': 826, 'W1329': 827, 'W2300': 828, 'W2338': 829, 'W2339': 830, 'W317': 831, 'W438': 832, 'W1078': 833, 'W2340': 834, 'W2341': 835, 'W2345': 836, 'W2346': 837, 'W1362': 838, 'W23': 839, 'W2347': 840, 'W2348': 841, 'W2349': 842, 'W452': 843, 'W1206': 844, 'W909': 845, 'W2355': 846, 'W2356': 847, 'W788': 848, 'W1580': 849, 'W254': 850, 'W1848': 851, 'W2357': 852, 'W1482': 853, 'W2358': 854, 'W1282': 855, 'W1053': 856, 'W2359': 857, 'W1544': 858, 'W2360': 859, 'W2361': 860, 'W2362': 861, 'W982': 862, 'W2208': 863, 'W2363': 864, 'W2378': 865, 'W1775': 866, 'W2379': 867, 'W2372': 868, 'W2074': 869, 'W2385': 870, 'W2377': 871, 'D13': 872, 'W905': 873, 'W1105': 874, 'W2396': 875, 'W2172': 876, 'W2397': 877, 'W2398': 878, 'W145': 879, 'W181': 880, 'W2399': 881, 'W2402': 882, 'W1931': 883, 'W1795': 884, 'W608': 885, 'W2407': 886, 'W2408': 887, 'W2409': 888, 'W109': 889, 'W1119': 890, 'W2410': 891, 'W322': 892, 'W2422': 893, 'W2412': 894, 'W2423': 895, 'W765': 896, 'W2451': 897, 'W2474': 898, 'W2475': 899, 'W2476': 900, 'W2477': 901, 'W2505': 902, 'W2506': 903, 'W2507': 904, 'W2508': 905, 'W1283': 906, 'W2509': 907, 'W2510': 908, 'W2555': 909, 'W537': 910, 'W1294': 911, 'W2556': 912, 'W2563': 913, 'W1895': 914, 'W2564': 915, 'W2565': 916, 'W2567': 917, 'W2568': 918, 'W2569': 919, 'W616': 920, 'W2572': 921, 'W2220': 922, 'W2573': 923, 'W2261': 924, 'W2574': 925, 'W2575': 926, 'W2576': 927, 'W2577': 928, 'W2578': 929, 'W2579': 930, 'W2580': 931, 'W2581': 932, 'W644': 933, 'W1094': 934, 'W2582': 935, 'W2103': 936, 'W2583': 937, 'W2584': 938, 'W2585': 939, 'W2586': 940, 'W912': 941, 'W1379': 942, 'W1061': 943, 'W501': 944, 'W2587': 945, 'W299': 946, 'W774': 947, 'W2227': 948, 'W1065': 949, 'W2605': 950, 'W2606': 951, 'W2607': 952, 'W2608': 953, 'W2609': 954, 'W939': 955, 'W2610': 956, 'D21': 957, 'W2611': 958, 'W2612': 959, 'W1548': 960, 'W725': 961, 'W2645': 962, 'W2637': 963, 'W2649': 964, 'W1905': 965, 'W2650': 966, 'W1588': 967, 'W2429': 968, 'W302': 969, 'W2692': 970, 'W2654': 971, 'W2678': 972, 'W2697': 973, 'W2696': 974, 'W2698': 975, 'W1536': 976, 'W2740': 977, 'W2741': 978, 'W2742': 979, 'W2743': 980, 'W2744': 981, 'D27': 982, 'W2768': 983, 'W1524': 984, 'W2769': 985, 'W2253': 986, 'W1932': 987, 'W2775': 988, 'W2776': 989, 'W275': 990, 'W2653': 991, 'W2777': 992, 'W1109': 993, 'W247': 994, 'W150': 995, 'W2778': 996, 'W2779': 997, 'W2780': 998, 'W749': 999, 'W2792': 1000, 'W2793': 1001, 'W2794': 1002, 'W776': 1003, 'W2746': 1004, 'W2795': 1005, 'W1161': 1006, 'W2329': 1007, 'W1375': 1008, 'W2672': 1009, 'W1410': 1010, 'W999': 1011, 'W2823': 1012, 'W2824': 1013, 'W2640': 1014, 'W2825': 1015, 'W2826': 1016, 'W1856': 1017, 'W2831': 1018, 'W2787': 1019, 'W2832': 1020, 'W721': 1021, 'W2842': 1022, 'W1079': 1023, 'W2843': 1024, 'W2887': 1025, 'W1515': 1026, 'W2888': 1027, 'W2882': 1028, 'W2889': 1029, 'W630': 1030, 'W2890': 1031, 'W2187': 1032, 'W2896': 1033, 'W2897': 1034, 'W634': 1035, 'W2892': 1036, 'W2893': 1037, 'W1904': 1038, 'W2757': 1039, 'W2898': 1040, 'W2899': 1041, 'W263': 1042, 'W2288': 1043, 'W2905': 1044, 'W388': 1045, 'W2940': 1046, 'W2941': 1047, 'W2942': 1048, 'W2943': 1049, 'W2944': 1050, 'W2945': 1051, 'W2844': 1052, 'W933': 1053, 'W969': 1054, 'W120': 1055, 'W2032': 1056, 'W2929': 1057, 'W2936': 1058, 'W2106': 1059, 'W2949': 1060, 'W1751': 1061, 'W736': 1062, 'W1727': 1063, 'W416': 1064, 'W2954': 1065, 'W2955': 1066, 'W2956': 1067, 'W2957': 1068, 'W592': 1069, 'W2964': 1070, 'W1732': 1071, 'W2756': 1072, 'W1643': 1073, 'W2978': 1074, 'W962': 1075, 'W2990': 1076, 'W723': 1077, 'W2991': 1078, 'W1430': 1079, 'W2900': 1080, 'W2992': 1081, 'W2993': 1082, 'W2965': 1083, 'W1235': 1084, 'W2994': 1085, 'W2995': 1086, 'W2765': 1087, 'W1613': 1088, 'W3002': 1089, 'W3003': 1090, 'W1419': 1091, 'W3011': 1092, 'W2988': 1093, 'W3010': 1094, 'W1827': 1095, 'W1027': 1096, 'W1028': 1097, 'W996': 1098, 'W3012': 1099, 'W3013': 1100, 'W3007': 1101, 'W886': 1102, 'W2107': 1103, 'W2178': 1104, 'W1692': 1105, 'W6': 1106, 'W399': 1107, 'W3024': 1108, 'W2966': 1109, 'W2729': 1110, 'W1175': 1111, 'W1016': 1112, 'W469': 1113, 'D7': 1114, 'W1471': 1115, 'W1545': 1116, 'W2234': 1117, 'W3066': 1118, 'W3067': 1119, 'W754': 1120, 'W1364': 1121, 'W356': 1122, 'W2869': 1123, 'W3068': 1124, 'W3069': 1125, 'W3070': 1126, 'W3074': 1127, 'W3075': 1128, 'W3076': 1129, 'W3084': 1130, 'W881': 1131, 'W419': 1132, 'W3085': 1133, 'W3086': 1134, 'W3087': 1135, 'W1636': 1136, 'W3088': 1137, 'W2008': 1138, 'W432': 1139, 'W3089': 1140, 'W3090': 1141, 'W3107': 1142, 'W1936': 1143, 'W3108': 1144, 'W2210': 1145, 'W3098': 1146, 'W3109': 1147, 'W3110': 1148, 'W2214': 1149, 'W2324': 1150, 'W3116': 1151, 'W3117': 1152, 'W1513': 1153, 'W1450': 1154, 'W3118': 1155, 'W3119': 1156, 'W3120': 1157, 'W3121': 1158, 'W3122': 1159, 'W2485': 1160, 'W3123': 1161, 'W3124': 1162, 'W3125': 1163, 'W2073': 1164, 'W3142': 1165, 'W3143': 1166, 'W3152': 1167, 'W3149': 1168, 'W3153': 1169, 'W3154': 1170, 'W3155': 1171, 'W3156': 1172, 'W2159': 1173, 'W2542': 1174, 'W3164': 1175, 'W3165': 1176, 'W3161': 1177, 'W3180': 1178, 'W3181': 1179, 'W3182': 1180, 'W3183': 1181, 'W240': 1182, 'W3184': 1183, 'W3185': 1184, 'W3186': 1185, 'W1543': 1186, 'W413': 1187, 'W3187': 1188, 'W3188': 1189, 'W1154': 1190, 'W3189': 1191, 'W3190': 1192, 'W3192': 1193, 'W3193': 1194, 'W326': 1195, 'W3194': 1196, 'W3195': 1197, 'W3141': 1198, 'W269': 1199, 'W1674': 1200, 'W3196': 1201, 'W3197': 1202, 'W3198': 1203, 'W3199': 1204, 'W3200': 1205, 'W3201': 1206, 'W3202': 1207, 'W3203': 1208, 'W1438': 1209, 'W3206': 1210, 'W3207': 1211, 'W3208': 1212, 'W2122': 1213, 'W3140': 1214, 'W3169': 1215, 'W3213': 1216, 'W1267': 1217, 'W3146': 1218, 'W3216': 1219, 'W3227': 1220, 'W2035': 1221, 'W1009': 1222, 'W3218': 1223, 'W3228': 1224, 'W3229': 1225, 'W1038': 1226, 'W3167': 1227, 'W3231': 1228, 'W2406': 1229, 'W2158': 1230, 'W2591': 1231, 'W2113': 1232, 'W552': 1233, 'W2557': 1234, 'W649': 1235, 'W418': 1236, 'W278': 1237, 'W3247': 1238, 'W3248': 1239, 'W3249': 1240, 'W2080': 1241, 'W3252': 1242, 'W3253': 1243, 'W3267': 1244, 'W3268': 1245, 'W2139': 1246, 'W3168': 1247, 'W3269': 1248, 'W3270': 1249, 'W3271': 1250, 'W1133': 1251, 'W3272': 1252, 'W3273': 1253, 'W1066': 1254, 'W2910': 1255, 'W1363': 1256, 'W3274': 1257, 'W3275': 1258, 'W703': 1259, 'W1365': 1260, 'W2401': 1261, 'W3264': 1262, 'W3276': 1263, 'W1470': 1264, 'W3277': 1265, 'W3278': 1266, 'W3279': 1267, 'W3280': 1268, 'W3281': 1269, 'W3286': 1270, 'W3287': 1271, 'W1606': 1272, 'W3288': 1273, 'W3292': 1274, 'W3293': 1275, 'W3294': 1276, 'W3295': 1277, 'W1852': 1278, 'W2886': 1279, 'W3296': 1280, 'W3297': 1281, 'W3298': 1282, 'W3299': 1283, 'W1220': 1284, 'W2553': 1285, 'W3309': 1286, 'W3112': 1287, 'W2486': 1288, 'W3321': 1289, 'W3300': 1290, 'W3301': 1291, 'W3324': 1292, 'W2391': 1293, 'W3325': 1294, 'W3326': 1295, 'W3342': 1296, 'W3343': 1297, 'W3344': 1298, 'W3345': 1299, 'W3346': 1300, 'W3347': 1301, 'W2961': 1302, 'W3386': 1303, 'W568': 1304, 'W3394': 1305, 'W2498': 1306, 'W3402': 1307, 'W3403': 1308, 'W3404': 1309, 'W3405': 1310, 'W2552': 1311, 'W3406': 1312, 'W3407': 1313, 'W952': 1314, 'W1242': 1315, 'W141': 1316, 'W3384': 1317, 'W1060': 1318, 'W3422': 1319, 'W3423': 1320, 'W3425': 1321, 'W3426': 1322, 'W3427': 1323, 'W3428': 1324, 'W3429': 1325, 'W298': 1326, 'W3265': 1327, 'W3319': 1328, 'W3320': 1329, 'W488': 1330, 'W3504': 1331, 'W543': 1332, 'W3505': 1333, 'W3506': 1334, 'W3507': 1335, 'W1733': 1336, 'W2342': 1337, 'W3283': 1338, 'W566': 1339, 'W679': 1340, 'W2461': 1341, 'W3171': 1342, 'W3510': 1343, 'W1093': 1344, 'W1658': 1345, 'W1521': 1346, 'W3511': 1347, 'W3512': 1348, 'W3376': 1349, 'W3513': 1350, 'W623': 1351, 'W3516': 1352, 'W3517': 1353, 'W3520': 1354, 'W2531': 1355, 'W1361': 1356, 'W916': 1357, 'W2251': 1358, 'W3521': 1359, 'W3444': 1360, 'W3445': 1361, 'W3522': 1362, 'W3525': 1363, 'W3526': 1364, 'W3527': 1365, 'W3528': 1366, 'W3456': 1367, 'W3529': 1368, 'W3530': 1369, 'W3531': 1370, 'W2297': 1371, 'W3535': 1372, 'W3536': 1373, 'W3537': 1374, 'W500': 1375, 'W3538': 1376, 'W3539': 1377, 'W3540': 1378, 'W3541': 1379, 'W3214': 1380, 'W3545': 1381, 'W1527': 1382, 'W3546': 1383, 'W421': 1384, 'W858': 1385, 'W3547': 1386, 'W3548': 1387, 'W3549': 1388, 'W3554': 1389, 'W3328': 1390, 'W3555': 1391, 'W3556': 1392, 'W3557': 1393, 'W3558': 1394, 'W1601': 1395, 'W3518': 1396, 'W3564': 1397, 'W3565': 1398, 'W2722': 1399, 'W3562': 1400, 'W3563': 1401, 'W3566': 1402, 'W1896': 1403, 'W3572': 1404, 'W3573': 1405, 'W1401': 1406, 'W3574': 1407, 'D32': 1408, 'W1871': 1409, 'W3575': 1410, 'W3576': 1411, 'W3577': 1412, 'W3578': 1413, 'W1562': 1414, 'W3451': 1415, 'W2671': 1416, 'W3582': 1417, 'W3606': 1418, 'W3614': 1419, 'W3487': 1420, 'W3615': 1421, 'W3616': 1422, 'W3618': 1423, 'W3619': 1424, 'W3620': 1425, 'W3621': 1426, 'W3622': 1427, 'W3623': 1428, 'W3624': 1429, 'W3625': 1430, 'W1099': 1431, 'W3626': 1432, 'W3550': 1433, 'W567': 1434, 'W3631': 1435, 'W3629': 1436, 'W3630': 1437, 'W3586': 1438, 'W3635': 1439, 'W722': 1440, 'W3644': 1441, 'W2644': 1442, 'W3645': 1443, 'W747': 1444, 'W2543': 1445, 'W3636': 1446, 'W3647': 1447, 'W2588': 1448, 'W3640': 1449, 'W1424': 1450, 'W1335': 1451, 'W3648': 1452, 'W3649': 1453, 'W2833': 1454, 'W786': 1455, 'W3650': 1456, 'W1945': 1457, 'W2232': 1458, 'W3651': 1459, 'W3652': 1460, 'W3628': 1461, 'W3653': 1462, 'W3654': 1463, 'W3158': 1464, 'W3655': 1465, 'W3656': 1466, 'W1288': 1467, 'W3660': 1468, 'W3661': 1469, 'W3662': 1470, 'W3663': 1471, 'W3664': 1472, 'W3665': 1473, 'W3666': 1474, 'W1940': 1475, 'W3667': 1476, 'W3668': 1477, 'W3681': 1478, 'W3682': 1479, 'W3683': 1480, 'W1031': 1481, 'W3689': 1482, 'W3690': 1483, 'W3691': 1484, 'W3692': 1485, 'W3042': 1486, 'W1216': 1487, 'W1713': 1488, 'W3693': 1489, 'W3484': 1490, 'W3694': 1491, 'W3695': 1492, 'W3696': 1493, 'W3697': 1494, 'W3698': 1495, 'W3699': 1496, 'W3700': 1497, 'W3701': 1498, 'W3718': 1499, 'W3719': 1500, 'W2160': 1501, 'W3727': 1502, 'W3728': 1503, 'W3729': 1504, 'W3730': 1505, 'W3731': 1506, 'W2808': 1507, 'W3732': 1508, 'W633': 1509, 'W2658': 1510, 'W1357': 1511, 'W3748': 1512, 'W3749': 1513, 'W3750': 1514, 'W3397': 1515, 'W3751': 1516, 'W3752': 1517, 'W1869': 1518, 'W1435': 1519, 'W2732': 1520, 'W3543': 1521, 'W3234': 1522, 'W3753': 1523, 'W2277': 1524, 'W3754': 1525, 'W75': 1526, 'W3755': 1527, 'W3756': 1528, 'W3757': 1529, 'W3332': 1530, 'W708': 1531, 'W3449': 1532, 'W3758': 1533, 'W3759': 1534, 'W1893': 1535, 'W3764': 1536, 'W2034': 1537, 'W3761': 1538, 'W1780': 1539, 'W2554': 1540, 'W3768': 1541, 'W3769': 1542, 'W3603': 1543, 'W3784': 1544, 'W1331': 1545, 'W3785': 1546, 'W3786': 1547, 'W3787': 1548, 'W3788': 1549, 'W3789': 1550, 'W3790': 1551, 'W3791': 1552, 'W3781': 1553, 'W3799': 1554, 'W3802': 1555, 'W3803': 1556, 'W3804': 1557, 'W3805': 1558, 'W3806': 1559, 'W3815': 1560, 'W3816': 1561, 'W3820': 1562, 'W3821': 1563, 'W3822': 1564, 'W968': 1565, 'W1637': 1566, 'W3823': 1567, 'W3825': 1568, 'W2247': 1569, 'W3826': 1570, 'W3827': 1571, 'W3284': 1572, 'W2730': 1573, 'W1145': 1574, 'W3848': 1575, 'W3849': 1576, 'W2870': 1577, 'W3290': 1578, 'W3850': 1579, 'W3851': 1580, 'W3289': 1581, 'W103': 1582, 'W3852': 1583, 'W3854': 1584, 'W873': 1585, 'W3462': 1586, 'W3855': 1587, 'D18': 1588, 'W1356': 1589, 'W18': 1590, 'W3856': 1591, 'W3857': 1592, 'W1767': 1593, 'W3858': 1594, 'W2181': 1595, 'W3859': 1596, 'W3633': 1597, 'W3860': 1598, 'W3861': 1599, 'W3862': 1600, 'W3863': 1601, 'W3864': 1602, 'W3865': 1603, 'W3866': 1604, 'W1382': 1605, 'W3867': 1606, 'W3868': 1607, 'W3869': 1608, 'W3870': 1609, 'W3080': 1610, 'W3051': 1611, 'W789': 1612, 'W3871': 1613, 'W3872': 1614, 'W3874': 1615, 'W1316': 1616, 'W1269': 1617, 'W2369': 1618, 'W3890': 1619, 'W3891': 1620, 'W888': 1621, 'W3892': 1622, 'W3893': 1623, 'W3897': 1624, 'W3898': 1625, 'W3901': 1626, 'W3902': 1627, 'W3903': 1628, 'W3904': 1629, 'W990': 1630, 'W3905': 1631, 'W3907': 1632, 'W3908': 1633, 'W3909': 1634, 'W3910': 1635, 'W3911': 1636, 'W3912': 1637, 'W1769': 1638, 'W3896': 1639, 'W645': 1640, 'W1870': 1641, 'W1546': 1642, 'W151': 1643, 'W3920': 1644, 'W3809': 1645, 'W3810': 1646, 'W3929': 1647, 'W1030': 1648, 'W3930': 1649, 'W3931': 1650, 'W3932': 1651, 'W1968': 1652, 'W2389': 1653, 'W3933': 1654, 'W3934': 1655, 'W3935': 1656, 'W3936': 1657, 'W3937': 1658, 'W651': 1659, 'W1881': 1660, 'W3938': 1661, 'W3939': 1662, 'W3466': 1663, 'W3949': 1664, 'W3950': 1665, 'W3951': 1666, 'W3952': 1667, 'W3953': 1668, 'W3954': 1669, 'W3923': 1670, 'W3560': 1671, 'W3955': 1672, 'W3956': 1673, 'W3957': 1674, 'W3958': 1675, 'W3959': 1676, 'W3960': 1677, 'W1738': 1678, 'W3600': 1679, 'W2518': 1680, 'W3968': 1681, 'W3977': 1682, 'W3978': 1683, 'W1935': 1684, 'W3979': 1685, 'W3980': 1686, 'W3989': 1687, 'W3990': 1688, 'W625': 1689, 'W2020': 1690, 'W4006': 1691, 'W4007': 1692, 'W2292': 1693, 'W2018': 1694, 'W4012': 1695, 'W4013': 1696, 'W4014': 1697, 'W4015': 1698, 'W4025': 1699, 'W1736': 1700, 'W4028': 1701, 'W3706': 1702, 'W2856': 1703, 'W3000': 1704, 'W2140': 1705, 'W2274': 1706, 'W4038': 1707, 'W4039': 1708, 'W1722': 1709, 'W359': 1710, 'W3580': 1711, 'W3581': 1712, 'W4046': 1713, 'W599': 1714, 'W600': 1715, 'W4047': 1716, 'W4048': 1717, 'W4049': 1718, 'W4050': 1719, 'W4051': 1720, 'W4052': 1721, 'W277': 1722, 'W440': 1723, 'W3739': 1724, 'W4080': 1725, 'W1808': 1726, 'W4081': 1727, 'W4082': 1728, 'W4083': 1729, 'W527': 1730, 'W4066': 1731, 'W678': 1732, 'W3114': 1733, 'W4105': 1734, 'W4110': 1735, 'W921': 1736, 'W249': 1737, 'W1276': 1738, 'W4114': 1739, 'W4115': 1740, 'W4116': 1741, 'W1353': 1742, 'W4117': 1743, 'W3079': 1744, 'W4118': 1745, 'W4119': 1746, 'W4120': 1747, 'W4123': 1748, 'W4094': 1749, 'W4126': 1750, 'W4127': 1751, 'W3137': 1752, 'W4128': 1753, 'W4129': 1754, 'W2559': 1755, 'W4130': 1756, 'W118': 1757, 'W4139': 1758, 'W4140': 1759, 'W4141': 1760, 'W1954': 1761, 'W3465': 1762, 'W1621': 1763, 'W2239': 1764, 'W4145': 1765, 'W4144': 1766, 'W1169': 1767, 'W1408': 1768, 'W4146': 1769, 'W4147': 1770, 'W4148': 1771, 'W250': 1772, 'W4159': 1773, 'W4160': 1774, 'W4161': 1775, 'W4097': 1776, 'W4162': 1777, 'W955': 1778, 'W1737': 1779, 'W4034': 1780, 'W14': 1781, 'W238': 1782, 'W4163': 1783, 'W4164': 1784, 'W4168': 1785, 'W4169': 1786, 'W4170': 1787, 'W4171': 1788, 'W4172': 1789, 'W4173': 1790, 'W3524': 1791, 'W4176': 1792, 'W4078': 1793, 'W1876': 1794, 'W4177': 1795, 'W3948': 1796, 'W4178': 1797, 'W4179': 1798, 'W4180': 1799, 'W4181': 1800, 'W4158': 1801, 'W2760': 1802, 'W4196': 1803, 'W1915': 1804, 'W719': 1805, 'W4135': 1806, 'W4199': 1807, 'W2570': 1808, 'W1111': 1809, 'W4200': 1810, 'W4201': 1811, 'W4202': 1812, 'W4203': 1813, 'W4204': 1814, 'W4205': 1815, 'W4206': 1816, 'W4207': 1817, 'W1477': 1818, 'W1818': 1819, 'W4208': 1820, 'W2061': 1821, 'W1793': 1822, 'W4221': 1823, 'W4231': 1824, 'W4232': 1825, 'W2677': 1826, 'W1747': 1827, 'W1122': 1828, 'W4258': 1829, 'W4265': 1830, 'W688': 1831, 'W4266': 1832, 'W4238': 1833, 'W4267': 1834, 'W4268': 1835, 'W4273': 1836, 'W4274': 1837, 'W4275': 1838, 'W1861': 1839, 'W4276': 1840, 'W4277': 1841, 'W1444': 1842, 'W4278': 1843, 'W4279': 1844, 'W4283': 1845, 'W400': 1846, 'W4186': 1847, 'W4284': 1848, 'W1957': 1849, 'W4285': 1850, 'W2382': 1851, 'W4288': 1852, 'W4289': 1853, 'W1847': 1854, 'W4290': 1855, 'W4291': 1856, 'W4315': 1857, 'W615': 1858, 'W4316': 1859, 'W767': 1860, 'W768': 1861, 'W4319': 1862, 'W497': 1863, 'W4333': 1864, 'W4334': 1865, 'W4346': 1866, 'W4347': 1867, 'W4348': 1868, 'W3972': 1869, 'W2248': 1870, 'W899': 1871, 'W887': 1872, 'W3596': 1873, 'W4143': 1874, 'W4349': 1875, 'W4213': 1876, 'W4350': 1877, 'W4336': 1878, 'W4351': 1879, 'W2063': 1880, 'W414': 1881, 'W4352': 1882, 'W16': 1883, 'W2782': 1884, 'W4004': 1885, 'W3358': 1886, 'W4353': 1887, 'W548': 1888, 'W4122': 1889, 'W4354': 1890, 'W551': 1891, 'W456': 1892, 'W4355': 1893, 'W3162': 1894, 'W4356': 1895, 'W4357': 1896, 'W1843': 1897, 'W395': 1898, 'W2752': 1899, 'W1326': 1900, 'W1091': 1901, 'W4384': 1902, 'W4385': 1903, 'W2296': 1904, 'W2169': 1905, 'W520': 1906, 'W3131': 1907, 'W2982': 1908, 'W2188': 1909, 'W4306': 1910, 'W4395': 1911, 'W4396': 1912, 'W2293': 1913, 'W4397': 1914, 'W4042': 1915, 'W4057': 1916, 'W1452': 1917, 'W1046': 1918, 'W4407': 1919, 'W1299': 1920, 'W4408': 1921, 'W1437': 1922, 'W4409': 1923, 'W3842': 1924, 'W4410': 1925, 'W4411': 1926, 'W737': 1927, 'W3113': 1928, 'W4413': 1929, 'W3795': 1930, 'W4414': 1931, 'W4423': 1932, 'W4386': 1933, 'W2710': 1934, 'W4424': 1935, 'W4427': 1936, 'W4428': 1937, 'W4437': 1938, 'W1866': 1939, 'W4344': 1940, 'W4043': 1941, 'W726': 1942, 'W1520': 1943, 'W4451': 1944, 'W4454': 1945, 'W355': 1946, 'W903': 1947, 'W4462': 1948, 'W3942': 1949, 'W601': 1950, 'W4463': 1951, 'W4464': 1952, 'W4477': 1953, 'W902': 1954, 'W1039': 1955, 'W3714': 1956, 'W4478': 1957, 'W4479': 1958, 'W4480': 1959, 'W911': 1960, 'W4493': 1961, 'W2200': 1962, 'W2979': 1963, 'W4512': 1964, 'W4469': 1965, 'W4513': 1966, 'W4217': 1967, 'W4544': 1968, 'W4567': 1969, 'W256': 1970, 'W1814': 1971, 'W4391': 1972, 'W4470': 1973, 'W965': 1974, 'W4579': 1975, 'W4582': 1976, 'W4583': 1977, 'W4584': 1978, 'W4585': 1979, 'W4598': 1980, 'W763': 1981, 'W4599': 1982, 'W1373': 1983, 'W1605': 1984, 'W1008': 1985, 'W4596': 1986, 'W447': 1987, 'W4495': 1988, 'W2901': 1989, 'W1164': 1990, 'W4524': 1991, 'W4318': 1992, 'W4531': 1993, 'W943': 1994, 'W3016': 1995, 'W1547': 1996, 'W4607': 1997, 'W4537': 1998, 'W2094': 1999, 'W4663': 2000, 'W4665': 2001, 'W4670': 2002, 'W4671': 2003, 'W4666': 2004, 'W4667': 2005, 'W4672': 2006, 'W4561': 2007, 'W4560': 2008, 'W4562': 2009, 'W4563': 2010, 'W4696': 2011, 'W4697': 2012, 'W319': 2013, 'W4698': 2014, 'W4699': 2015, 'W4700': 2016, 'W4624': 2017, 'W4701': 2018, 'W4702': 2019, 'W4703': 2020, 'W4704': 2021, 'W4684': 2022, 'W4705': 2023, 'W4706': 2024, 'W607': 2025, 'W4525': 2026, 'W4707': 2027, 'W4553': 2028, 'W4559': 2029, 'W2380': 2030, 'W4716': 2031, 'W2706': 2032, 'W4725': 2033, 'W593': 2034, 'W4719': 2035, 'W2987': 2036, 'W4726': 2037, 'W3446': 2038, 'W4721': 2039, 'W4722': 2040, 'W4723': 2041, 'W4735': 2042, 'W4736': 2043, 'W4676': 2044, 'W4738': 2045, 'W4739': 2046, 'W4740': 2047, 'W2516': 2048, 'W4741': 2049, 'W4728': 2050, 'W2411': 2051, 'W2515': 2052, 'W4742': 2053, 'W67': 2054, 'W4492': 2055, 'W2281': 2056, 'W4752': 2057, 'W1874': 2058, 'W4724': 2059, 'W182': 2060, 'W4749': 2061, 'W563': 2062, 'W4766': 2063, 'W4503': 2064, 'W4504': 2065, 'W4767': 2066, 'W4764': 2067, 'W4768': 2068, 'W4165': 2069, 'W4771': 2070, 'W4772': 2071, 'W4773': 2072, 'W4777': 2073, 'W4778': 2074, 'W845': 2075, 'W4538': 2076, 'W2344': 2077, 'W4574': 2078, 'W4801': 2079, 'W4802': 2080, 'W4803': 2081, 'W4577': 2082, 'W4228': 2083, 'W560': 2084, 'W4309': 2085, 'W4824': 2086, 'W1691': 2087, 'W1116': 2088, 'W4834': 2089, 'W635': 2090, 'W4746': 2091, 'W4747': 2092, 'W1554': 2093, 'W3448': 2094, 'W192': 2095, 'W4849': 2096, 'W4850': 2097, 'W693': 2098, 'W4848': 2099, 'W2805': 2100, 'W591': 2101, 'W3469': 2102, 'W4528': 2103, 'W4304': 2104, 'W576': 2105, 'W4359': 2106, 'W4857': 2107, 'W556': 2108, 'W4858': 2109, 'W1723': 2110, 'W4649': 2111, 'W4532': 2112, 'W1789': 2113, 'W3050': 2114, 'W4862': 2115, 'W178': 2116, 'W757': 2117, 'W2835': 2118, 'W4720': 2119, 'W4575': 2120, 'W4863': 2121, 'W1457': 2122, 'W900': 2123, 'W841': 2124, 'W4854': 2125, 'W4618': 2126, 'W4534': 2127, 'W4808': 2128, 'W3144': 2129, 'W4873': 2130, 'W4874': 2131, 'W1015': 2132, 'W4879': 2133, 'W690': 2134, 'W4880': 2135, 'W4881': 2136, 'W4708': 2137, 'W3459': 2138, 'W4882': 2139, 'W4883': 2140, 'W2666': 2141, 'W506': 2142, 'W4888': 2143, 'W4889': 2144, 'W3588': 2145, 'W4890': 2146, 'W4898': 2147, 'W4901': 2148, 'W4902': 2149, 'W1753': 2150, 'W4916': 2151, 'W4244': 2152, 'W1853': 2153, 'W4917': 2154, 'W3502': 2155, 'W4918': 2156, 'W4920': 2157, 'W4921': 2158, 'W953': 2159, 'W1045': 2160, 'W4682': 2161, 'W3329': 2162, 'W4926': 2163, 'W485': 2164, 'W1107': 2165, 'W248': 2166, 'W4927': 2167, 'W4928': 2168, 'W4944': 2169, 'W1743': 2170, 'W4945': 2171, 'W4946': 2172, 'W4947': 2173, 'W2201': 2174, 'W2453': 2175, 'W1555': 2176, 'W4948': 2177, 'W4971': 2178, 'W4965': 2179, 'W4966': 2180, 'W4964': 2181, 'W4972': 2182, 'W4973': 2183, 'W4974': 2184, 'W4963': 2185, 'W4979': 2186, 'W4980': 2187, 'W4967': 2188, 'W4981': 2189, 'W4983': 2190, 'W3671': 2191, 'W4990': 2192, 'W1648': 2193, 'W4989': 2194, 'W5005': 2195, 'W1707': 2196, 'W5006': 2197, 'W4994': 2198, 'W5007': 2199, 'W4756': 2200, 'W5008': 2201, 'W5009': 2202, 'W5010': 2203, 'W5011': 2204, 'W5012': 2205, 'W5019': 2206, 'W5020': 2207, 'W5025': 2208, 'W3306': 2209, 'W1834': 2210, 'W5026': 2211, 'W5033': 2212, 'W5028': 2213, 'W5034': 2214, 'W5037': 2215, 'W4286': 2216, 'W5038': 2217, 'W3072': 2218, 'W5052': 2219, 'W5053': 2220, 'W5056': 2221, 'W2463': 2222, 'W5058': 2223, 'W3967': 2224, 'W2141': 2225, 'W3381': 2226, 'W2071': 2227, 'W5076': 2228, 'W2446': 2229, 'W5077': 2230, 'W5078': 2231, 'W5079': 2232, 'W5080': 2233, 'W5081': 2234, 'W5082': 2235, 'W5083': 2236, 'W5084': 2237, 'W5085': 2238, 'W5086': 2239, 'W2109': 2240, 'W1478': 2241, 'W3945': 2242, 'W5094': 2243, 'W2464': 2244, 'W5070': 2245, 'W706': 2246, 'W5095': 2247, 'W5096': 2248, 'W5087': 2249, 'W5100': 2250, 'W5101': 2251, 'W5102': 2252, 'W1047': 2253, 'W3408': 2254, 'W5112': 2255, 'W5113': 2256, 'W5075': 2257, 'W5114': 2258, 'W4361': 2259, 'W4498': 2260, 'W5115': 2261, 'W1213': 2262, 'W5116': 2263, 'W5117': 2264, 'W5118': 2265, 'W5119': 2266, 'W5120': 2267, 'W3263': 2268, 'W890': 2269, 'W1202': 2270, 'W5122': 2271, 'W2544': 2272, 'W5123': 2273, 'W5124': 2274, 'W5125': 2275, 'W5126': 2276, 'W5127': 2277, 'W3023': 2278, 'W5128': 2279, 'W5129': 2280, 'W5130': 2281, 'W5131': 2282, 'W5132': 2283, 'W5133': 2284, 'W5136': 2285, 'W2602': 2286, 'W5138': 2287, 'W2872': 2288, 'W545': 2289, 'W5139': 2290, 'W5107': 2291, 'W5140': 2292, 'W5141': 2293, 'W1777': 2294, 'W5142': 2295, 'W5044': 2296, 'W2599': 2297, 'W5144': 2298, 'W5145': 2299, 'W5146': 2300, 'W5147': 2301, 'W5150': 2302, 'W5047': 2303, 'W538': 2304, 'W2772': 2305, 'W4593': 2306, 'W5046': 2307, 'W5152': 2308, 'W684': 2309, 'W5163': 2310, 'W5164': 2311, 'W5165': 2312, 'W5166': 2313, 'W5167': 2314, 'W5168': 2315, 'W2590': 2316, 'W5157': 2317, 'W5169': 2318, 'W5158': 2319, 'W5159': 2320, 'W5170': 2321, 'W5160': 2322, 'W5161': 2323, 'W5171': 2324, 'W2443': 2325, 'W5162': 2326, 'W5172': 2327, 'W5173': 2328, 'W4068': 2329, 'W5174': 2330, 'W5175': 2331, 'W5176': 2332, 'W5177': 2333, 'W4941': 2334, 'W2350': 2335, 'W5178': 2336, 'W5185': 2337, 'W1934': 2338, 'W1358': 2339, 'W5186': 2340, 'W5187': 2341, 'W5201': 2342, 'W5202': 2343, 'W5203': 2344, 'W913': 2345, 'W2656': 2346, 'W3410': 2347, 'W5204': 2348, 'W5205': 2349, 'W3553': 2350, 'W5196': 2351, 'W5210': 2352, 'W5211': 2353, 'W1651': 2354, 'W5212': 2355, 'W5198': 2356, 'W5213': 2357, 'W5214': 2358, 'W5215': 2359, 'W5216': 2360, 'W5217': 2361, 'W5218': 2362, 'W5219': 2363, 'W5220': 2364, 'W4418': 2365, 'W5206': 2366, 'W5221': 2367, 'W1514': 2368, 'W5222': 2369, 'W5223': 2370, 'W5224': 2371, 'W3219': 2372, 'W4526': 2373, 'W5226': 2374, 'W5227': 2375, 'W1188': 2376, 'W5228': 2377, 'W5229': 2378, 'W5230': 2379, 'W5231': 2380, 'W5232': 2381, 'W4251': 2382, 'W4000': 2383, 'W5233': 2384, 'W2478': 2385, 'W639': 2386, 'W5234': 2387, 'W5235': 2388, 'W5236': 2389, 'W2705': 2390, 'W5237': 2391, 'W5238': 2392, 'W5239': 2393, 'W5240': 2394, 'W3049': 2395, 'W5241': 2396, 'W2598': 2397, 'W2418': 2398, 'W5242': 2399, 'W5245': 2400, 'W5246': 2401, 'W5247': 2402, 'W5248': 2403, 'W5250': 2404, 'W5251': 2405, 'W5252': 2406, 'W5253': 2407, 'W5254': 2408, 'W4280': 2409, 'W5261': 2410, 'W5258': 2411, 'W436': 2412, 'W5262': 2413, 'W3392': 2414, 'W5263': 2415, 'W5264': 2416, 'W5265': 2417, 'W3092': 2418, 'W1649': 2419, 'W5267': 2420, 'W5268': 2421, 'W2750': 2422, 'W108': 2423, 'W5269': 2424, 'W5274': 2425, 'W5275': 2426, 'W5276': 2427, 'W5277': 2428, 'W5278': 2429, 'W5279': 2430, 'W5280': 2431, 'W1926': 2432, 'W5281': 2433, 'W5282': 2434, 'W5283': 2435, 'W5284': 2436, 'W5285': 2437, 'W5286': 2438, 'W1886': 2439, 'W5287': 2440, 'W5288': 2441, 'W605': 2442, 'W2783': 2443, 'W5291': 2444, 'W5292': 2445, 'W5293': 2446, 'W5294': 2447, 'W5295': 2448, 'W1947': 2449, 'W2083': 2450, 'W5296': 2451, 'W3743': 2452, 'W5297': 2453, 'W4937': 2454, 'W1557': 2455, 'W4293': 2456, 'W5298': 2457, 'W5299': 2458, 'W3254': 2459, 'W2019': 2460, 'W4417': 2461, 'W5301': 2462, 'W5303': 2463, 'W5304': 2464, 'W5305': 2465, 'W5306': 2466, 'W5307': 2467, 'W5308': 2468, 'W5310': 2469, 'W5311': 2470, 'W1446': 2471, 'W4331': 2472, 'W5325': 2473, 'W4476': 2474, 'W5329': 2475, 'W5330': 2476, 'W5331': 2477, 'W2702': 2478, 'W4262': 2479, 'W5342': 2480, 'W3613': 2481, 'W5352': 2482, 'W4605': 2483, 'W1981': 2484, 'W5353': 2485, 'W5354': 2486, 'W1019': 2487, 'W5355': 2488, 'W5356': 2489, 'W5357': 2490, 'W5358': 2491, 'W4259': 2492, 'W5359': 2493, 'W4789': 2494, 'W5360': 2495, 'W5367': 2496, 'W5368': 2497, 'W5337': 2498, 'W5370': 2499, 'W5371': 2500, 'W5373': 2501, 'W5374': 2502, 'W941': 2503, 'W5024': 2504, 'W5375': 2505, 'W5376': 2506, 'W1186': 2507, 'W5377': 2508, 'W5378': 2509, 'W3814': 2510, 'W5379': 2511, 'W4627': 2512, 'W5380': 2513, 'W5381': 2514, 'W5383': 2515, 'W5384': 2516, 'W5385': 2517, 'W5386': 2518, 'W5387': 2519, 'W5389': 2520, 'W5390': 2521, 'W5391': 2522, 'W5392': 2523, 'W1918': 2524, 'W5399': 2525, 'W1770': 2526, 'W1807': 2527, 'W5403': 2528, 'W5404': 2529, 'W5405': 2530, 'W5406': 2531, 'W5408': 2532, 'W5409': 2533, 'W5410': 2534, 'W5411': 2535, 'W5412': 2536, 'W5413': 2537, 'W5414': 2538, 'W5415': 2539, 'W3970': 2540, 'W5416': 2541, 'W1889': 2542, 'W5417': 2543, 'W1971': 2544, 'W5418': 2545, 'W5419': 2546, 'W4261': 2547, 'W5420': 2548, 'W2528': 2549, 'W5421': 2550, 'W5422': 2551, 'W5423': 2552, 'W5424': 2553, 'W5425': 2554, 'W5346': 2555, 'W5426': 2556, 'W5427': 2557, 'W5428': 2558, 'W5429': 2559, 'W5430': 2560, 'W4693': 2561, 'W4505': 2562, 'W199': 2563, 'W1022': 2564, 'W5431': 2565, 'W5432': 2566}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2567"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##print(\"words : \", words)\n",
    "\n",
    "# 중복단어 제거\n",
    "words = list(dict.fromkeys(words))\n",
    "\n",
    "# 각 단어별 일련번호\n",
    "word_to_id = {\"[PAD]\": 0, \"[UNK]\": 1}\n",
    "for w in words:\n",
    "    word_to_id[w] = len(word_to_id)\n",
    "\n",
    "# 각 번호별 단어\n",
    "id_to_word = {i: w for w, i in word_to_id.items()}\n",
    "\n",
    "print(word_to_id)\n",
    "len(word_to_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b50770",
   "metadata": {
    "papermill": {
     "duration": 0.006199,
     "end_time": "2023-03-22T17:52:06.854198",
     "exception": false,
     "start_time": "2023-03-22T17:52:06.847999",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load train_set and Divide the train_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc956ab8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T17:52:06.869071Z",
     "iopub.status.busy": "2023-03-22T17:52:06.867889Z",
     "iopub.status.idle": "2023-03-22T17:52:06.884061Z",
     "shell.execute_reply": "2023-03-22T17:52:06.882966Z"
    },
    "papermill": {
     "duration": 0.026118,
     "end_time": "2023-03-22T17:52:06.886506",
     "exception": false,
     "start_time": "2023-03-22T17:52:06.860388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['W25 W26 W27 W19 W28 W29 W30 W31 W32 W33 W34 W35 W36 W37 W38 W39 W24 W40',\n",
       "  'W41 W4 W42 W43 W44 W45 W46 W47 W48 W49 W50 W51 W52 W53 W17 W54 W24',\n",
       "  'W55 W19 W46 W32 W32 W56 W57 W58 W59 W19 W13 W60 W19 W13 W61 W62',\n",
       "  'W13 W83 W32 W32 W56 W57 W13 W84 W19 W28 W85 W86 W24',\n",
       "  'W87 W88 W89 W90 W32 W91 W13 W92 W93 W90 W94 W95 W24',\n",
       "  'W13 W52 W32 W53 W17 W13 W96 W97 W10 W2 W98 W99 W19 W13 W100 W24',\n",
       "  'W122 W123 W110 W124 W125 W19 W13 W126 W127 W128 W32 W129 W130 W36 W13 W131 W132 W17 W133 W24',\n",
       "  'W1 W2 W3 W4 W134 W7 W28 W78 W19 W13 W135 W136 W137 W138 W139 W90 W17 W140 W24',\n",
       "  'W154 W155 W134 W47 W139 W28 W156 W157 W97 W90 W158 W159 W46 W32 W154 W46 W160 W161 W24',\n",
       "  'W17 W162 W12 W163 W144 W12 W55 W164 W165 W32 W166 W167 W46 W168 W32 W169 W24',\n",
       "  'W134 W7 W28 W201 W12 W202 W203 W12 W204 W205 W24',\n",
       "  'W46 W206 W7 W8 W207 W208 W12 W28 W209 W210 W19 W28 W211 W19 W13 W212 W213 W17 W205 W24',\n",
       "  'W90 W214 W32 W206 W7 W17 W13 W215 W24',\n",
       "  'W55 W131 W212 W216 W47 W32 W7 W17 W13 W217 W218 W97 W28 W219 W24',\n",
       "  'W134 W21 W220 W221 W28 W215 W45 W222 W223 W224 W12 W225 W226 W42 W227 W24',\n",
       "  'W228 W19 W46 W32 W204 W13 W229 W213 W97 W32 W230 W142 W19 W13 W220 W231 W24',\n",
       "  'W13 W279 W280 W122 W47 W281 W282 W271 W36 W283 W28 W284 W24',\n",
       "  'W26 W285 W32 W28 W286 W228 W97 W287 W288 W24',\n",
       "  'W289 W17 W290 W291 W122 W32 W292 W293 W24',\n",
       "  'W296 W47 W32 W303 W304 W305 W64 W12 W306 W12 W307 W90 W308 W19 W309 W93 W310 W97 W311 W24'],\n",
       " 900,\n",
       " ['D11',\n",
       "  'D1',\n",
       "  'D3',\n",
       "  'D20',\n",
       "  'D20',\n",
       "  'D20',\n",
       "  'D20',\n",
       "  'D1',\n",
       "  'D20',\n",
       "  'D20',\n",
       "  'D20',\n",
       "  'D12',\n",
       "  'D20',\n",
       "  'D15',\n",
       "  'D15',\n",
       "  'D4',\n",
       "  'D20',\n",
       "  'D20',\n",
       "  'D5',\n",
       "  'D16'],\n",
       " 900)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################   TRAIN   ################################\n",
    "\n",
    "with open(\"/kaggle/input/2023-nlp-lab1-problem1/simple_seq.train.csv\") as f:\n",
    "    lines = f.read()\n",
    "    lines = \"\".join([s for s in lines.strip().splitlines(True) if s.strip()])\n",
    "    first = lines.split('\\n', -1)\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    for i in range(len(first)):\n",
    "        strings = first[i].replace(\" \",\"\")\n",
    "        strings = first[i].split(',', -1)\n",
    "        strings = [v for v in strings if v]         # 빈요소 \"\" 제거 \n",
    "        label_list.append(strings.pop())\n",
    "        strings = \" \".join(strings)\n",
    "        data_list.append(strings)\n",
    "        \n",
    "data_list[0:20], len(data_list), label_list[0:20], len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3aeacfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T17:52:06.901916Z",
     "iopub.status.busy": "2023-03-22T17:52:06.901485Z",
     "iopub.status.idle": "2023-03-22T17:52:06.918394Z",
     "shell.execute_reply": "2023-03-22T17:52:06.917357Z"
    },
    "papermill": {
     "duration": 0.027495,
     "end_time": "2023-03-22T17:52:06.920825",
     "exception": false,
     "start_time": "2023-03-22T17:52:06.893330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   2,    3,    4, ...,   19,    0,    0],\n",
       "        [  21,   22,   23, ...,    0,    0,    0],\n",
       "        [  38,    5,   27, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 199,  737, 1415, ...,    0,    0,    0],\n",
       "        [ 199,  328, 2563, ...,    0,    0,    0],\n",
       "        [ 199,   28,   16, ...,    0,    0,    0]]),\n",
       " (900, 20))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 일련번호 데이터\n",
    "train_inputs = []\n",
    "for s in data_list:                                 ##### 문장별 반복 \n",
    "    row = [word_to_id[w] for w in s.split()]\n",
    "##    print(row)                                    ##### 번호 나열\n",
    "    row += [0] * (20 - len(row))                    ##### padding, later we use pad id in dictionary\n",
    "    train_inputs.append(row)\n",
    "train_inputs = np.array(train_inputs)\n",
    "\n",
    "train_inputs, train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92e1cb04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T17:52:06.936277Z",
     "iopub.status.busy": "2023-03-22T17:52:06.935389Z",
     "iopub.status.idle": "2023-03-22T17:52:06.945514Z",
     "shell.execute_reply": "2023-03-22T17:52:06.944428Z"
    },
    "papermill": {
     "duration": 0.020527,
     "end_time": "2023-03-22T17:52:06.947985",
     "exception": false,
     "start_time": "2023-03-22T17:52:06.927458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 20],\n",
       "        [ 37],\n",
       "        [ 47],\n",
       "        [ 52],\n",
       "        [ 52],\n",
       "        [ 52],\n",
       "        [ 52],\n",
       "        [ 37],\n",
       "        [ 52],\n",
       "        [ 52],\n",
       "        [ 52],\n",
       "        [125],\n",
       "        [ 52],\n",
       "        [132],\n",
       "        [132],\n",
       "        [147],\n",
       "        [ 52],\n",
       "        [ 52],\n",
       "        [164],\n",
       "        [176]]),\n",
       " (900, 1))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_inputs = []\n",
    "for s in label_list:\n",
    "    row = [word_to_id[w] for w in s.split()]\n",
    "    label_inputs.append(row)\n",
    "label_inputs = np.array(label_inputs)\n",
    "label_inputs[0:20], label_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d02f035",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T17:52:06.963630Z",
     "iopub.status.busy": "2023-03-22T17:52:06.962857Z",
     "iopub.status.idle": "2023-03-22T17:52:06.979309Z",
     "shell.execute_reply": "2023-03-22T17:52:06.978333Z"
    },
    "papermill": {
     "duration": 0.026873,
     "end_time": "2023-03-22T17:52:06.981634",
     "exception": false,
     "start_time": "2023-03-22T17:52:06.954761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]]),\n",
       " (2567, 2567))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_metrix = np.eye(len(word_to_id))   \n",
    "onehot_metrix, onehot_metrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "175a6b6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T17:52:06.997970Z",
     "iopub.status.busy": "2023-03-22T17:52:06.997109Z",
     "iopub.status.idle": "2023-03-22T17:52:07.166708Z",
     "shell.execute_reply": "2023-03-22T17:52:07.165499Z"
    },
    "papermill": {
     "duration": 0.180608,
     "end_time": "2023-03-22T17:52:07.169223",
     "exception": false,
     "start_time": "2023-03-22T17:52:06.988615",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((900, 20, 2567), (900, 1, 2567))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_onehots = onehot_metrix[train_inputs]\n",
    "label_onehots = onehot_metrix[label_inputs]\n",
    "\n",
    "train_onehots.shape, label_onehots.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "153d9502",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T17:52:07.186028Z",
     "iopub.status.busy": "2023-03-22T17:52:07.185497Z",
     "iopub.status.idle": "2023-03-22T17:52:07.195156Z",
     "shell.execute_reply": "2023-03-22T17:52:07.194122Z"
    },
    "papermill": {
     "duration": 0.021162,
     "end_time": "2023-03-22T17:52:07.197493",
     "exception": false,
     "start_time": "2023-03-22T17:52:07.176331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " (900, 51340),\n",
       " array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " (900, 2567))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_train_onehots = train_onehots.reshape(train_onehots.shape[0],train_onehots.shape[1]*train_onehots.shape[2])\n",
    "flatten_label_onehots= label_onehots.reshape(label_onehots.shape[0],label_onehots.shape[2])\n",
    "\n",
    "X_train = flatten_train_onehots\n",
    "y_train = flatten_label_onehots\n",
    "\n",
    "X_train, X_train.shape, y_train, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231fb371",
   "metadata": {
    "papermill": {
     "duration": 0.006869,
     "end_time": "2023-03-22T17:52:07.211485",
     "exception": false,
     "start_time": "2023-03-22T17:52:07.204616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1582769",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T17:52:07.227928Z",
     "iopub.status.busy": "2023-03-22T17:52:07.227026Z",
     "iopub.status.idle": "2023-03-22T17:52:07.241474Z",
     "shell.execute_reply": "2023-03-22T17:52:07.240614Z"
    },
    "papermill": {
     "duration": 0.024815,
     "end_time": "2023-03-22T17:52:07.243502",
     "exception": false,
     "start_time": "2023-03-22T17:52:07.218687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W13 W81 W19 W346 W846 W1582 W70 W28 W5433 W19 W1163 W2261 W24',\n",
       " 'W5413 W111 W5414 W32 W68 W5415 W12 W2402 W19 W5438 W5439 W5440 W12 W346 W240 W5441 W5442 W24',\n",
       " 'W5413 W111 W5414 W32 W68 W5415 W12 W417 W346 W336 W17 W28 W5443 W12 W122 W47 W38 W335 W1248 W24',\n",
       " 'W5413 W111 W5414 W32 W68 W5415 W12 W346 W32 W2833 W93 W28 W5444 W5445 W17 W346 W5446 W24',\n",
       " 'W5413 W111 W5414 W32 W68 W5415 W12 W111 W346 W47 W336 W286 W5415 W552 W5447 W641 W346 W24',\n",
       " 'W5413 W111 W5414 W32 W68 W5415 W12 W346 W168 W2464 W5448 W24',\n",
       " 'W87 W31 W47 W38 W1196 W97 W627 W5449',\n",
       " 'W447 W28 W498 W204 W2590 W5451 W24',\n",
       " 'W475 W32 W246 W337 W1254 W1198 W461',\n",
       " 'W110 W904 W90 W110 W904 W87 W38 W498 W90 W81 W97 W15 W1065 W555 W475 W90 W47 W38 W280 W24']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###########################   TEST_SET   ######################################\n",
    "with open(\"/kaggle/input/2023-nlp-lab1-problem1/simple_seq.test.csv\") as f:\n",
    "    lines = f.read() ##Assume the sample file has 3 lines\n",
    "    lines = \"\".join([s for s in lines.strip().splitlines(True) if s.strip()])\n",
    "    first = lines.split('\\n', -1)\n",
    "    test_list = []\n",
    "    for i in range(len(first)):\n",
    "        strings = first[i].replace(\" \",\"\")\n",
    "        strings = first[i].split(',', -1)\n",
    "        strings = [v for v in strings if v]         # 빈요소 \"\" 제거 \n",
    "        strings = \" \".join(strings)\n",
    "        test_list.append(strings)\n",
    "        \n",
    "test_list[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7c62745",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T17:52:07.260401Z",
     "iopub.status.busy": "2023-03-22T17:52:07.259794Z",
     "iopub.status.idle": "2023-03-22T17:52:07.269826Z",
     "shell.execute_reply": "2023-03-22T17:52:07.268692Z"
    },
    "papermill": {
     "duration": 0.021312,
     "end_time": "2023-03-22T17:52:07.272262",
     "exception": false,
     "start_time": "2023-03-22T17:52:07.250950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  43,  802,    5, ...,    0,    0,    0],\n",
       "        [2537,  328, 2538, ...,   18,    0,    0],\n",
       "        [2537,  328, 2538, ...,  188,  727,   18],\n",
       "        ...,\n",
       "        [ 205,  355,   59, ...,    0,    0,    0],\n",
       "        [  55,   53,  403, ...,    0,    0,    0],\n",
       "        [   1,  102,   71, ...,    0,    0,    0]]),\n",
       " (100, 20))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_inputs = []\n",
    "for s in test_list:\n",
    "    row = []\n",
    "    for w in s.split():\n",
    "        if w in word_to_id:\n",
    "            row.append(word_to_id[w])\n",
    "        else:\n",
    "            row.append(word_to_id['[UNK]'])  # 'W846' 대신 'UNK'를 사용\n",
    "    row += [0] * (20 - len(row))\n",
    "    test_inputs.append(row)\n",
    "test_inputs = np.array(test_inputs)\n",
    "\n",
    "test_inputs, test_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3db0c169",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T17:52:07.288859Z",
     "iopub.status.busy": "2023-03-22T17:52:07.288396Z",
     "iopub.status.idle": "2023-03-22T17:52:07.306007Z",
     "shell.execute_reply": "2023-03-22T17:52:07.304823Z"
    },
    "papermill": {
     "duration": 0.028705,
     "end_time": "2023-03-22T17:52:07.308365",
     "exception": false,
     "start_time": "2023-03-22T17:52:07.279660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 1., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 1., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 1., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 1.]]),\n",
       " (2567, 2567))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_metrix = np.eye(len(word_to_id))   \n",
    "onehot_metrix, onehot_metrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c91f6696",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T17:52:07.325440Z",
     "iopub.status.busy": "2023-03-22T17:52:07.325047Z",
     "iopub.status.idle": "2023-03-22T17:52:07.353583Z",
     "shell.execute_reply": "2023-03-22T17:52:07.352412Z"
    },
    "papermill": {
     "duration": 0.039839,
     "end_time": "2023-03-22T17:52:07.356024",
     "exception": false,
     "start_time": "2023-03-22T17:52:07.316185",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "        [[0., 1., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         [0., 0., 0., ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.],\n",
       "         [1., 0., 0., ..., 0., 0., 0.]]]),\n",
       " (100, 20, 2567))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_onehots = onehot_metrix[test_inputs]\n",
    "test_onehots, test_onehots.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82c729ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T17:52:07.373001Z",
     "iopub.status.busy": "2023-03-22T17:52:07.372579Z",
     "iopub.status.idle": "2023-03-22T17:52:07.381420Z",
     "shell.execute_reply": "2023-03-22T17:52:07.380365Z"
    },
    "papermill": {
     "duration": 0.019889,
     "end_time": "2023-03-22T17:52:07.383621",
     "exception": false,
     "start_time": "2023-03-22T17:52:07.363732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.]]),\n",
       " (100, 51340))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten_test_onehots = test_onehots.reshape(test_onehots.shape[0],test_onehots.shape[1]*test_onehots.shape[2])\n",
    "\n",
    "X_test = flatten_test_onehots\n",
    "\n",
    "X_test, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "797507c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T17:52:07.400716Z",
     "iopub.status.busy": "2023-03-22T17:52:07.400361Z",
     "iopub.status.idle": "2023-03-22T17:52:07.410027Z",
     "shell.execute_reply": "2023-03-22T17:52:07.409160Z"
    },
    "papermill": {
     "duration": 0.020857,
     "end_time": "2023-03-22T17:52:07.412181",
     "exception": false,
     "start_time": "2023-03-22T17:52:07.391324",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class DenseLayer(Layer):\n",
    "    def __init__(self, units, activation='sigmoid', kernel_initializer='glorot_uniform', **kwargs):\n",
    "        super(DenseLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = activation\n",
    "        self.kernel_initializer = kernel_initializer\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(name='kernel', shape=(input_shape[-1], self.units), initializer=self.kernel_initializer, trainable=True)\n",
    "        self.bias = self.add_weight(name='bias', shape=(self.units,), initializer='zeros', trainable=True)\n",
    "        super(DenseLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        outputs = tf.matmul(inputs, self.kernel) + self.bias\n",
    "        if self.activation:\n",
    "            activation_layer = Activation(self.activation)\n",
    "            outputs = activation_layer(outputs)\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.units)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3c87efe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T17:52:07.429810Z",
     "iopub.status.busy": "2023-03-22T17:52:07.428888Z",
     "iopub.status.idle": "2023-03-22T18:03:35.012435Z",
     "shell.execute_reply": "2023-03-22T18:03:35.010538Z"
    },
    "papermill": {
     "duration": 687.596029,
     "end_time": "2023-03-22T18:03:35.016110",
     "exception": false,
     "start_time": "2023-03-22T17:52:07.420081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 8s 533ms/step - loss: 7.9001 - accuracy: 0.0000e+00 - val_loss: 7.7855 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 7s 512ms/step - loss: 7.8633 - accuracy: 0.0000e+00 - val_loss: 7.7862 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 7s 519ms/step - loss: 7.8208 - accuracy: 0.0037 - val_loss: 7.7866 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 7s 539ms/step - loss: 7.7860 - accuracy: 0.0049 - val_loss: 7.7868 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 7s 512ms/step - loss: 7.7467 - accuracy: 0.0173 - val_loss: 7.7867 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 7s 512ms/step - loss: 7.7096 - accuracy: 0.0259 - val_loss: 7.7865 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 7s 517ms/step - loss: 7.6731 - accuracy: 0.0370 - val_loss: 7.7861 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 7s 536ms/step - loss: 7.6349 - accuracy: 0.0519 - val_loss: 7.7854 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 7s 514ms/step - loss: 7.5951 - accuracy: 0.0642 - val_loss: 7.7846 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 7s 511ms/step - loss: 7.5608 - accuracy: 0.0728 - val_loss: 7.7835 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 7s 517ms/step - loss: 7.5198 - accuracy: 0.0901 - val_loss: 7.7822 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 7s 514ms/step - loss: 7.4859 - accuracy: 0.1037 - val_loss: 7.7807 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 7s 547ms/step - loss: 7.4421 - accuracy: 0.1358 - val_loss: 7.7790 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 7s 518ms/step - loss: 7.4018 - accuracy: 0.1753 - val_loss: 7.7771 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 7s 517ms/step - loss: 7.3585 - accuracy: 0.1975 - val_loss: 7.7750 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 7s 512ms/step - loss: 7.3124 - accuracy: 0.2321 - val_loss: 7.7724 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 7s 528ms/step - loss: 7.2787 - accuracy: 0.2741 - val_loss: 7.7696 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 7s 541ms/step - loss: 7.2258 - accuracy: 0.3123 - val_loss: 7.7664 - val_accuracy: 0.0444\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 7s 517ms/step - loss: 7.1796 - accuracy: 0.3481 - val_loss: 7.7628 - val_accuracy: 0.1000\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 7s 525ms/step - loss: 7.1335 - accuracy: 0.3790 - val_loss: 7.7588 - val_accuracy: 0.1444\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 7s 516ms/step - loss: 7.0869 - accuracy: 0.4099 - val_loss: 7.7542 - val_accuracy: 0.1556\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 7s 544ms/step - loss: 7.0362 - accuracy: 0.4383 - val_loss: 7.7493 - val_accuracy: 0.1889\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 7s 528ms/step - loss: 6.9811 - accuracy: 0.4617 - val_loss: 7.7437 - val_accuracy: 0.2333\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 7s 531ms/step - loss: 6.9193 - accuracy: 0.5037 - val_loss: 7.7372 - val_accuracy: 0.2333\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 7s 532ms/step - loss: 6.8604 - accuracy: 0.5358 - val_loss: 7.7298 - val_accuracy: 0.2889\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 7s 516ms/step - loss: 6.7996 - accuracy: 0.5654 - val_loss: 7.7216 - val_accuracy: 0.3333\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 7s 545ms/step - loss: 6.7334 - accuracy: 0.5889 - val_loss: 7.7124 - val_accuracy: 0.3556\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 7s 521ms/step - loss: 6.6715 - accuracy: 0.6049 - val_loss: 7.7014 - val_accuracy: 0.4222\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 7s 518ms/step - loss: 6.6030 - accuracy: 0.6160 - val_loss: 7.6886 - val_accuracy: 0.4667\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 7s 521ms/step - loss: 6.5340 - accuracy: 0.6543 - val_loss: 7.6747 - val_accuracy: 0.4333\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 7s 546ms/step - loss: 6.4513 - accuracy: 0.6790 - val_loss: 7.6590 - val_accuracy: 0.4667\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 7s 532ms/step - loss: 6.3788 - accuracy: 0.6975 - val_loss: 7.6410 - val_accuracy: 0.4667\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 7s 521ms/step - loss: 6.2957 - accuracy: 0.7136 - val_loss: 7.6214 - val_accuracy: 0.4667\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 7s 517ms/step - loss: 6.2206 - accuracy: 0.7321 - val_loss: 7.5969 - val_accuracy: 0.4667\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 7s 524ms/step - loss: 6.1276 - accuracy: 0.7481 - val_loss: 7.5701 - val_accuracy: 0.4778\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 7s 553ms/step - loss: 6.0484 - accuracy: 0.7630 - val_loss: 7.5400 - val_accuracy: 0.4889\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 7s 520ms/step - loss: 5.9587 - accuracy: 0.7716 - val_loss: 7.5054 - val_accuracy: 0.5000\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 7s 524ms/step - loss: 5.8630 - accuracy: 0.7889 - val_loss: 7.4676 - val_accuracy: 0.4889\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 7s 527ms/step - loss: 5.7608 - accuracy: 0.8123 - val_loss: 7.4273 - val_accuracy: 0.4889\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 7s 525ms/step - loss: 5.6580 - accuracy: 0.8173 - val_loss: 7.3789 - val_accuracy: 0.4889\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 7s 544ms/step - loss: 5.5576 - accuracy: 0.8272 - val_loss: 7.3259 - val_accuracy: 0.5111\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 7s 519ms/step - loss: 5.4550 - accuracy: 0.8370 - val_loss: 7.2792 - val_accuracy: 0.5222\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 7s 521ms/step - loss: 5.3408 - accuracy: 0.8333 - val_loss: 7.2151 - val_accuracy: 0.5111\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 7s 523ms/step - loss: 5.2558 - accuracy: 0.8346 - val_loss: 7.1474 - val_accuracy: 0.5111\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 7s 543ms/step - loss: 5.1327 - accuracy: 0.8457 - val_loss: 7.0752 - val_accuracy: 0.5222\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 7s 522ms/step - loss: 5.0133 - accuracy: 0.8457 - val_loss: 7.0016 - val_accuracy: 0.5333\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 7s 522ms/step - loss: 4.9047 - accuracy: 0.8432 - val_loss: 6.9282 - val_accuracy: 0.5333\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 7s 532ms/step - loss: 4.7895 - accuracy: 0.8630 - val_loss: 6.8364 - val_accuracy: 0.5333\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 7s 535ms/step - loss: 4.6725 - accuracy: 0.8593 - val_loss: 6.7573 - val_accuracy: 0.5333\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 7s 546ms/step - loss: 4.5739 - accuracy: 0.8593 - val_loss: 6.6513 - val_accuracy: 0.5222\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 7s 522ms/step - loss: 4.4384 - accuracy: 0.8691 - val_loss: 6.5602 - val_accuracy: 0.5333\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 7s 525ms/step - loss: 4.3242 - accuracy: 0.8753 - val_loss: 6.4623 - val_accuracy: 0.5111\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 7s 522ms/step - loss: 4.2459 - accuracy: 0.8617 - val_loss: 6.3618 - val_accuracy: 0.5222\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 7s 525ms/step - loss: 4.1033 - accuracy: 0.8778 - val_loss: 6.2936 - val_accuracy: 0.5333\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 7s 530ms/step - loss: 3.9886 - accuracy: 0.8765 - val_loss: 6.1940 - val_accuracy: 0.5222\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 7s 519ms/step - loss: 3.8996 - accuracy: 0.8741 - val_loss: 6.1156 - val_accuracy: 0.5222\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 7s 526ms/step - loss: 3.7978 - accuracy: 0.8802 - val_loss: 6.0336 - val_accuracy: 0.5333\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 7s 526ms/step - loss: 3.6633 - accuracy: 0.8840 - val_loss: 5.9368 - val_accuracy: 0.5222\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 7s 544ms/step - loss: 3.5849 - accuracy: 0.8840 - val_loss: 5.8746 - val_accuracy: 0.5444\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 7s 523ms/step - loss: 3.4515 - accuracy: 0.8877 - val_loss: 5.7830 - val_accuracy: 0.5667\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 7s 529ms/step - loss: 3.3724 - accuracy: 0.8840 - val_loss: 5.7483 - val_accuracy: 0.5667\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 7s 527ms/step - loss: 3.2707 - accuracy: 0.8852 - val_loss: 5.6902 - val_accuracy: 0.5556\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 7s 518ms/step - loss: 3.1439 - accuracy: 0.8914 - val_loss: 5.6078 - val_accuracy: 0.5333\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 7s 542ms/step - loss: 3.0699 - accuracy: 0.8840 - val_loss: 5.5567 - val_accuracy: 0.5333\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 7s 531ms/step - loss: 3.0013 - accuracy: 0.8852 - val_loss: 5.5132 - val_accuracy: 0.5556\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 7s 532ms/step - loss: 2.9037 - accuracy: 0.8815 - val_loss: 5.4505 - val_accuracy: 0.5556\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 7s 532ms/step - loss: 2.8161 - accuracy: 0.8963 - val_loss: 5.4195 - val_accuracy: 0.5222\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 7s 540ms/step - loss: 2.7319 - accuracy: 0.8938 - val_loss: 5.3647 - val_accuracy: 0.5444\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 7s 520ms/step - loss: 2.6152 - accuracy: 0.8988 - val_loss: 5.3329 - val_accuracy: 0.5111\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 7s 524ms/step - loss: 2.5633 - accuracy: 0.8975 - val_loss: 5.3100 - val_accuracy: 0.5111\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 7s 521ms/step - loss: 2.5327 - accuracy: 0.9012 - val_loss: 5.2718 - val_accuracy: 0.5333\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 7s 517ms/step - loss: 2.4371 - accuracy: 0.9037 - val_loss: 5.2421 - val_accuracy: 0.5333\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 7s 544ms/step - loss: 2.4061 - accuracy: 0.9037 - val_loss: 5.2249 - val_accuracy: 0.5111\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 7s 515ms/step - loss: 2.3159 - accuracy: 0.9037 - val_loss: 5.1866 - val_accuracy: 0.5222\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 7s 529ms/step - loss: 2.2434 - accuracy: 0.9062 - val_loss: 5.1656 - val_accuracy: 0.5111\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 7s 528ms/step - loss: 2.1654 - accuracy: 0.9136 - val_loss: 5.1390 - val_accuracy: 0.5111\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 7s 516ms/step - loss: 2.1046 - accuracy: 0.9123 - val_loss: 5.1188 - val_accuracy: 0.5111\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 7s 543ms/step - loss: 2.0626 - accuracy: 0.9136 - val_loss: 5.0870 - val_accuracy: 0.5333\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 7s 529ms/step - loss: 2.0960 - accuracy: 0.9136 - val_loss: 5.0720 - val_accuracy: 0.5556\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 7s 533ms/step - loss: 1.9706 - accuracy: 0.9198 - val_loss: 5.0464 - val_accuracy: 0.5222\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 7s 532ms/step - loss: 1.9315 - accuracy: 0.9136 - val_loss: 5.0274 - val_accuracy: 0.5444\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 7s 543ms/step - loss: 1.9283 - accuracy: 0.9148 - val_loss: 5.0120 - val_accuracy: 0.5444\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 7s 525ms/step - loss: 1.8596 - accuracy: 0.9173 - val_loss: 4.9914 - val_accuracy: 0.5556\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 7s 525ms/step - loss: 1.7929 - accuracy: 0.9198 - val_loss: 4.9816 - val_accuracy: 0.5333\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 7s 519ms/step - loss: 1.7607 - accuracy: 0.9099 - val_loss: 4.9595 - val_accuracy: 0.5556\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 7s 528ms/step - loss: 1.7060 - accuracy: 0.9272 - val_loss: 4.9448 - val_accuracy: 0.5444\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 7s 547ms/step - loss: 1.6779 - accuracy: 0.9247 - val_loss: 4.9322 - val_accuracy: 0.5444\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 7s 518ms/step - loss: 1.6774 - accuracy: 0.9148 - val_loss: 4.9224 - val_accuracy: 0.5667\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 7s 522ms/step - loss: 1.6171 - accuracy: 0.9309 - val_loss: 4.8928 - val_accuracy: 0.5556\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 7s 519ms/step - loss: 1.5478 - accuracy: 0.9284 - val_loss: 4.8926 - val_accuracy: 0.5667\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 7s 542ms/step - loss: 1.5524 - accuracy: 0.9272 - val_loss: 4.8800 - val_accuracy: 0.5667\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 7s 525ms/step - loss: 1.5097 - accuracy: 0.9358 - val_loss: 4.8717 - val_accuracy: 0.5556\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 7s 521ms/step - loss: 1.4724 - accuracy: 0.9247 - val_loss: 4.8541 - val_accuracy: 0.5667\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 7s 520ms/step - loss: 1.4568 - accuracy: 0.9395 - val_loss: 4.8393 - val_accuracy: 0.5556\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 7s 519ms/step - loss: 1.4259 - accuracy: 0.9407 - val_loss: 4.8207 - val_accuracy: 0.5333\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 7s 554ms/step - loss: 1.3819 - accuracy: 0.9395 - val_loss: 4.8150 - val_accuracy: 0.5333\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 7s 523ms/step - loss: 1.3508 - accuracy: 0.9420 - val_loss: 4.8020 - val_accuracy: 0.5444\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 7s 524ms/step - loss: 1.3078 - accuracy: 0.9407 - val_loss: 4.7962 - val_accuracy: 0.5333\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 7s 521ms/step - loss: 1.3007 - accuracy: 0.9407 - val_loss: 4.7893 - val_accuracy: 0.5444\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 7s 523ms/step - loss: 1.2850 - accuracy: 0.9444 - val_loss: 4.7837 - val_accuracy: 0.5333\n",
      "4/4 [==============================] - 0s 40ms/step\n",
      "train_onehots.shape, test_onehots.shape :  (900, 20, 2567) (100, 20, 2567)\n",
      "flatten_train_onehots.shape, flatten_test_onehots.shape :  (900, 51340) (100, 51340)\n",
      "[[0.00028068 0.00024602 0.00029881 ... 0.00032826 0.00035081 0.00030878]\n",
      " [0.00027729 0.00028312 0.00027436 ... 0.0002459  0.00027894 0.00023313]\n",
      " [0.00025903 0.00030834 0.00041629 ... 0.00032488 0.00029482 0.00031431]\n",
      " ...\n",
      " [0.00049723 0.00036718 0.00037706 ... 0.00040492 0.00052636 0.00042261]\n",
      " [0.00024325 0.00037664 0.00035987 ... 0.00033661 0.00022028 0.0002462 ]\n",
      " [0.00043845 0.00035581 0.00026736 ... 0.00029516 0.00041219 0.00036142]] (100, 2567)\n",
      "D20\n",
      "D16\n",
      "D12\n",
      "D12\n",
      "D16\n",
      "D12\n",
      "D12\n",
      "D1\n",
      "D15\n",
      "D20\n",
      "D12\n",
      "D20\n",
      "D15\n",
      "D15\n",
      "D12\n",
      "D20\n",
      "D20\n",
      "D15\n",
      "D15\n",
      "D15\n",
      "D20\n",
      "D12\n",
      "D1\n",
      "D20\n",
      "D20\n",
      "D1\n",
      "D16\n",
      "D15\n",
      "D20\n",
      "D20\n",
      "D15\n",
      "D12\n",
      "D28\n",
      "D12\n",
      "D12\n",
      "D12\n",
      "D1\n",
      "D1\n",
      "D15\n",
      "D12\n",
      "D20\n",
      "D15\n",
      "D12\n",
      "D15\n",
      "D20\n",
      "D12\n",
      "D15\n",
      "D1\n",
      "D20\n",
      "D1\n",
      "D15\n",
      "D12\n",
      "D12\n",
      "D12\n",
      "D12\n",
      "D20\n",
      "D15\n",
      "D20\n",
      "D15\n",
      "D12\n",
      "D12\n",
      "D28\n",
      "D15\n",
      "D20\n",
      "D20\n",
      "D12\n",
      "D1\n",
      "D20\n",
      "D20\n",
      "D20\n",
      "D20\n",
      "D1\n",
      "D15\n",
      "D12\n",
      "D12\n",
      "D12\n",
      "D15\n",
      "D20\n",
      "D12\n",
      "D20\n",
      "D15\n",
      "D1\n",
      "D20\n",
      "D1\n",
      "D1\n",
      "D1\n",
      "D1\n",
      "D12\n",
      "D12\n",
      "D28\n",
      "D28\n",
      "D12\n",
      "D12\n",
      "D12\n",
      "D12\n",
      "D20\n",
      "D12\n",
      "D20\n",
      "D12\n",
      "D16\n"
     ]
    }
   ],
   "source": [
    "def DeepNN(X_train, y_train, X_test):# ,sc):\n",
    "    # create a model \n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import Dense, Embedding, Flatten, BatchNormalization\n",
    "\n",
    "    learning_rate = 0.001\n",
    "    weight_decay = 0.0001\n",
    "    hidden_layer_1 = 1000\n",
    "    hidden_layer_2 = 100\n",
    "    input_dim = X_train.shape[1]\n",
    "    output_dim = y_train.shape[1]\n",
    "    \n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(DenseLayer(hidden_layer_1, activation='sigmoid', input_dim = X_train.shape[1], kernel_initializer=GlorotUniform()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(DenseLayer(hidden_layer_2, activation='sigmoid', kernel_initializer=GlorotUniform()))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(DenseLayer(output_dim, activation='softmax'))\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum=weight_decay, nesterov=True),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    hist_gru = model.fit(X_train, y_train, epochs=100, validation_split=0.1, batch_size=64)\n",
    "          \n",
    "    prediction = model.predict(X_test)\n",
    "\n",
    "    \n",
    "    return model, prediction, hist_gru\n",
    "\n",
    "\n",
    "model, prediction, hist_gru = DeepNN(X_train, y_train, X_test)#, sc)\n",
    "\n",
    "\n",
    "print(\"train_onehots.shape, test_onehots.shape : \", train_onehots.shape, test_onehots.shape)\n",
    "print(\"flatten_train_onehots.shape, flatten_test_onehots.shape : \", flatten_train_onehots.shape, flatten_test_onehots.shape)\n",
    "\n",
    "predicted_labels = np.argmax(prediction, axis=1)\n",
    "\n",
    "print(prediction,prediction.shape)\n",
    "\n",
    "pred_label_list = []\n",
    "for label in predicted_labels:\n",
    "    pred_label_list.append(id_to_word[label])\n",
    "    print(id_to_word[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ed56cc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-22T18:03:35.256344Z",
     "iopub.status.busy": "2023-03-22T18:03:35.255854Z",
     "iopub.status.idle": "2023-03-22T18:03:35.299241Z",
     "shell.execute_reply": "2023-03-22T18:03:35.297996Z"
    },
    "papermill": {
     "duration": 0.162809,
     "end_time": "2023-03-22T18:03:35.301947",
     "exception": false,
     "start_time": "2023-03-22T18:03:35.139138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S001</td>\n",
       "      <td>D20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S002</td>\n",
       "      <td>D16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S003</td>\n",
       "      <td>D12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S004</td>\n",
       "      <td>D12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S005</td>\n",
       "      <td>D16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>S096</td>\n",
       "      <td>D20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>S097</td>\n",
       "      <td>D12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>S098</td>\n",
       "      <td>D20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>S099</td>\n",
       "      <td>D12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>S100</td>\n",
       "      <td>D16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id pred\n",
       "0   S001  D20\n",
       "1   S002  D16\n",
       "2   S003  D12\n",
       "3   S004  D12\n",
       "4   S005  D16\n",
       "..   ...  ...\n",
       "95  S096  D20\n",
       "96  S097  D12\n",
       "97  S098  D20\n",
       "98  S099  D12\n",
       "99  S100  D16\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_list = []\n",
    "for i in range(1,len(pred_label_list)+1):\n",
    "    index_list.append(f\"S{i:03}\")\n",
    "\n",
    "#prediction = pd.DataFrame(pred_label_list, index = index_list)\n",
    "\n",
    "prediction = pd.DataFrame(columns=['id', 'pred'])\n",
    "\n",
    "prediction[\"id\"] = index_list\n",
    "prediction[\"pred\"] = pred_label_list\n",
    "\n",
    "prediction = prediction.reset_index(drop=True)\n",
    "\n",
    "#prediction = pd.DataFrame(pred_label_list, index=[f\"S{i:03}\" for i in range(1, len(pred_label_list)+1)])\n",
    "\n",
    "#prediction.columns = [\"id\",\"pred\"]\n",
    "#prediction.index = index_list\n",
    "prediction.to_csv('20221119_하준서_simple_seq.answer.csv', index = False)\n",
    "\n",
    "#index_list\n",
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 709.048896,
   "end_time": "2023-03-22T18:03:38.709942",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-22T17:51:49.661046",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
