{"cells":[{"cell_type":"code","execution_count":354,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-05-03T09:43:19.010072Z","iopub.status.busy":"2023-05-03T09:43:19.009588Z","iopub.status.idle":"2023-05-03T09:43:19.022068Z","shell.execute_reply":"2023-05-03T09:43:19.020566Z","shell.execute_reply.started":"2023-05-03T09:43:19.010032Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","#import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":355,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:19.025557Z","iopub.status.busy":"2023-05-03T09:43:19.024956Z","iopub.status.idle":"2023-05-03T09:43:20.694835Z","shell.execute_reply":"2023-05-03T09:43:20.693539Z","shell.execute_reply.started":"2023-05-03T09:43:19.025506Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[PAD]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ADP</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>PROPN</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>PART</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>SYM</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>PUNCT</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>NOUN</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>CCONJ</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>AUX</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>X</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>ADJ</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>ADV</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>VERB</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>SCONJ</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>DET</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>NUM</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>INTJ</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>PRON</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        0\n","0   [PAD]\n","1     ADP\n","2   PROPN\n","3    PART\n","4     SYM\n","5   PUNCT\n","6    NOUN\n","7   CCONJ\n","8     AUX\n","9       X\n","10    ADJ\n","11    ADV\n","12   VERB\n","13  SCONJ\n","14    DET\n","15    NUM\n","16   INTJ\n","17   PRON"]},"execution_count":355,"metadata":{},"output_type":"execute_result"}],"source":["import json\n","import pandas as pd\n","def read_json_file(file_path):\n","    with open(file_path, 'r') as f:\n","        data = json.load(f)\n","    return data\n","\n","train_set = read_json_file('./pos_datasets/train_set.json')\n","test_set = read_json_file('./pos_datasets/test_set.json')\n","word_dic_and_embedding = read_json_file('./pos_datasets/fasttext_word.json')\n","\n","tgt = pd.read_csv('./pos_datasets/tgt.txt', header=None )\n","\n","tgt\n","\n"]},{"cell_type":"code","execution_count":356,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:20.696571Z","iopub.status.busy":"2023-05-03T09:43:20.696230Z","iopub.status.idle":"2023-05-03T09:43:20.703428Z","shell.execute_reply":"2023-05-03T09:43:20.702555Z","shell.execute_reply.started":"2023-05-03T09:43:20.696537Z"},"trusted":true},"outputs":[{"data":{"text/plain":["({'tokens': ['Islam', 'Skilled'],\n","  'ud_tags': ['PROPN', 'PROPN'],\n","  'ptb_tags': ['NNP', 'NNP']},\n"," 12543)"]},"execution_count":356,"metadata":{},"output_type":"execute_result"}],"source":["train_set[\"0\"], len(train_set)"]},{"cell_type":"code","execution_count":357,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:20.706528Z","iopub.status.busy":"2023-05-03T09:43:20.706194Z","iopub.status.idle":"2023-05-03T09:43:20.715757Z","shell.execute_reply":"2023-05-03T09:43:20.714361Z","shell.execute_reply.started":"2023-05-03T09:43:20.706497Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(['Islam', 'Skilled'], ['PROPN', 'PROPN'], ['NNP', 'NNP'])"]},"execution_count":357,"metadata":{},"output_type":"execute_result"}],"source":["train_set[\"0\"][\"tokens\"], train_set[\"0\"][\"ud_tags\"], train_set[\"0\"][\"ptb_tags\"]  "]},{"cell_type":"code","execution_count":358,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:20.718017Z","iopub.status.busy":"2023-05-03T09:43:20.717250Z","iopub.status.idle":"2023-05-03T09:43:20.725139Z","shell.execute_reply":"2023-05-03T09:43:20.724287Z","shell.execute_reply.started":"2023-05-03T09:43:20.717963Z"},"trusted":true},"outputs":[{"data":{"text/plain":["({'tokens': ['complimented',\n","   'value',\n","   'Oprah',\n","   'cemented',\n","   'surfing',\n","   '90',\n","   'smarter',\n","   '973-3634',\n","   'Humanpixel',\n","   'cemented',\n","   'modernization',\n","   'begin']},\n"," 500)"]},"execution_count":358,"metadata":{},"output_type":"execute_result"}],"source":["test_set[\"0\"], len(test_set)"]},{"cell_type":"code","execution_count":359,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:20.726996Z","iopub.status.busy":"2023-05-03T09:43:20.726328Z","iopub.status.idle":"2023-05-03T09:43:20.735992Z","shell.execute_reply":"2023-05-03T09:43:20.735116Z","shell.execute_reply.started":"2023-05-03T09:43:20.726960Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(300, 19674)"]},"execution_count":359,"metadata":{},"output_type":"execute_result"}],"source":["len(word_dic_and_embedding[\"[PAD]\"]), len(word_dic_and_embedding)"]},{"cell_type":"code","execution_count":360,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:20.738590Z","iopub.status.busy":"2023-05-03T09:43:20.737398Z","iopub.status.idle":"2023-05-03T09:43:21.255137Z","shell.execute_reply":"2023-05-03T09:43:21.253914Z","shell.execute_reply.started":"2023-05-03T09:43:20.738540Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>...</th>\n","      <th>12533</th>\n","      <th>12534</th>\n","      <th>12535</th>\n","      <th>12536</th>\n","      <th>12537</th>\n","      <th>12538</th>\n","      <th>12539</th>\n","      <th>12540</th>\n","      <th>12541</th>\n","      <th>12542</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>tokens</th>\n","      <td>[Islam, Skilled]</td>\n","      <td>[origination, Great, attorney]</td>\n","      <td>[Figuratively, Others, fill, intents, installe...</td>\n","      <td>[Discovery, alarms, bag, dishonest, puff, arro...</td>\n","      <td>[read, 202.456.1111, versions, airliner, uplan...</td>\n","      <td>[frothing, perceiving, airliner, Color, ages, ...</td>\n","      <td>[rejuvenate, perceiving, yellow, Engine, shock...</td>\n","      <td>[stepped, Ordinarily, http://www.infoukes.com/...</td>\n","      <td>[withdrawing, Elizabeth, Lol, multi-national, ...</td>\n","      <td>[rift, Pacheco, 2545, 973-3634, Selah, JR, Ric...</td>\n","      <td>...</td>\n","      <td>[padded, slightly, fill, gunpowder, _, ingredi...</td>\n","      <td>[arrogant, Iris, Qaeda, arrogant, abt, arrogan...</td>\n","      <td>[rift, clan, alt.animals.horses.breeding, perc...</td>\n","      <td>[Oslo, clash, newsletter, della]</td>\n","      <td>[FAQ, Load, 973-3634, anyway, Cafe]</td>\n","      <td>[neoconservative, begin, school, conservation,...</td>\n","      <td>[southwestern, Horizon, Windsor, Game, comes, ...</td>\n","      <td>[NOTE, 01/13/2001, innovations, Traders, permi...</td>\n","      <td>[pyrimidal, Ordinarily, 973-3634, grandeur, un...</td>\n","      <td>[clan, quit, MORALITY, installed, quit, 01:09,...</td>\n","    </tr>\n","    <tr>\n","      <th>ud_tags</th>\n","      <td>[PROPN, PROPN]</td>\n","      <td>[NUM, NUM, NOUN]</td>\n","      <td>[NOUN, AUX, AUX, VERB, PUNCT, ADP, DET, NOUN, ...</td>\n","      <td>[PRON, NOUN, PART, NOUN, VERB, PUNCT, NOUN, VE...</td>\n","      <td>[PRON, AUX, VERB, DET, NOUN, NOUN, ADP, SCONJ,...</td>\n","      <td>[PRON, AUX, DET, NOUN, NOUN, VERB, ADP, PUNCT]</td>\n","      <td>[PRON, VERB, PRON, ADJ, ADP, DET, ADJ, NOUN, P...</td>\n","      <td>[PROPN, PART, NOUN, AUX, VERB, PART, VERB, SCO...</td>\n","      <td>[AUX, PRON, VERB, PRON, VERB, PART, VERB, ADJ,...</td>\n","      <td>[CCONJ, PART, VERB, DET, NOUN, ADP, DET, ADJ, ...</td>\n","      <td>...</td>\n","      <td>[PRON, AUX, AUX, ADJ, CCONJ, PRON, AUX, PART, ...</td>\n","      <td>[PUNCT, X, PUNCT, PUNCT, VERB, PUNCT, X, PUNCT...</td>\n","      <td>[CCONJ, SCONJ, NOUN, AUX, DET, NOUN, PUNCT, PR...</td>\n","      <td>[ADJ, PUNCT, NOUN, NOUN]</td>\n","      <td>[INTJ, VERB, DET, NOUN, PUNCT]</td>\n","      <td>[X, PUNCT, ADP, NOUN, NUM, PUNCT, NOUN, PUNCT,...</td>\n","      <td>[ADV, DET, ADJ, PROPN, NOUN, NOUN, PUNCT, INTJ...</td>\n","      <td>[CCONJ, DET, NOUN, PRON, VERB, X, NOUN, PRON, ...</td>\n","      <td>[ADV, AUX, DET, NOUN, SCONJ, VERB, ADV, PUNCT,...</td>\n","      <td>[SCONJ, PRON, VERB, PUNCT, PRON, AUX, PART, VE...</td>\n","    </tr>\n","    <tr>\n","      <th>ptb_tags</th>\n","      <td>[NNP, NNP]</td>\n","      <td>[CD, CD, NN]</td>\n","      <td>[NN, MD, VB, VBN, ,, IN, DT, NN, IN, DT, VBN, ...</td>\n","      <td>[PRP$, NN, POS, NN, VBZ, ``, NN, VBN, IN, JJ, ...</td>\n","      <td>[PRP, MD, VB, DT, NN, NN, IN, IN, VBG, DT, NN,...</td>\n","      <td>[WP, VBZ, DT, NN, NN, VBN, IN, .]</td>\n","      <td>[EX, VBZ, NN, JJ, IN, DT, JJ, NN, ,, CC, NN, R...</td>\n","      <td>[NNP, POS, NN, MD, VB, TO, VB, IN, PRP, VBP, D...</td>\n","      <td>[VBP, PRP, VB, PRP, VBP, TO, VB, JJR, .]</td>\n","      <td>[CC, TO, VB, DT, NN, IN, DT, JJ, NN, VBZ, TO, ...</td>\n","      <td>...</td>\n","      <td>[DT, MD, VB, JJ, CC, PRP, VBZ, RB, VB, ,, MD, ...</td>\n","      <td>[``, FW, ., '', VBZ, ``, FW, '', ,, CC, ``, PR...</td>\n","      <td>[CC, IN, NN, VBZ, DT, NN, ,, NN, MD, VB, IN, D...</td>\n","      <td>[JJ, HYPH, NN, NNS]</td>\n","      <td>[UH, VB, DT, NN, .]</td>\n","      <td>[LS, ., IN, NN, CD, ,, NN, -LRB-, NN, -RRB-, M...</td>\n","      <td>[RB, DT, JJ, NNP, NN, NN, ,, UH, .]</td>\n","      <td>[CC, DT, NN, PRP, VBP, GW, NN, PRP, MD, VB, IN...</td>\n","      <td>[RB, VBZ, DT, NN, IN, VBG, RB, ,, NN, .]</td>\n","      <td>[IN, PRP, VBP, ,, PRP, VBP, RB, VBG, .]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3 rows × 12543 columns</p>\n","</div>"],"text/plain":["                         0                               1   \n","tokens    [Islam, Skilled]  [origination, Great, attorney]  \\\n","ud_tags     [PROPN, PROPN]                [NUM, NUM, NOUN]   \n","ptb_tags        [NNP, NNP]                    [CD, CD, NN]   \n","\n","                                                          2   \n","tokens    [Figuratively, Others, fill, intents, installe...  \\\n","ud_tags   [NOUN, AUX, AUX, VERB, PUNCT, ADP, DET, NOUN, ...   \n","ptb_tags  [NN, MD, VB, VBN, ,, IN, DT, NN, IN, DT, VBN, ...   \n","\n","                                                          3   \n","tokens    [Discovery, alarms, bag, dishonest, puff, arro...  \\\n","ud_tags   [PRON, NOUN, PART, NOUN, VERB, PUNCT, NOUN, VE...   \n","ptb_tags  [PRP$, NN, POS, NN, VBZ, ``, NN, VBN, IN, JJ, ...   \n","\n","                                                          4   \n","tokens    [read, 202.456.1111, versions, airliner, uplan...  \\\n","ud_tags   [PRON, AUX, VERB, DET, NOUN, NOUN, ADP, SCONJ,...   \n","ptb_tags  [PRP, MD, VB, DT, NN, NN, IN, IN, VBG, DT, NN,...   \n","\n","                                                          5   \n","tokens    [frothing, perceiving, airliner, Color, ages, ...  \\\n","ud_tags      [PRON, AUX, DET, NOUN, NOUN, VERB, ADP, PUNCT]   \n","ptb_tags                  [WP, VBZ, DT, NN, NN, VBN, IN, .]   \n","\n","                                                          6   \n","tokens    [rejuvenate, perceiving, yellow, Engine, shock...  \\\n","ud_tags   [PRON, VERB, PRON, ADJ, ADP, DET, ADJ, NOUN, P...   \n","ptb_tags  [EX, VBZ, NN, JJ, IN, DT, JJ, NN, ,, CC, NN, R...   \n","\n","                                                          7   \n","tokens    [stepped, Ordinarily, http://www.infoukes.com/...  \\\n","ud_tags   [PROPN, PART, NOUN, AUX, VERB, PART, VERB, SCO...   \n","ptb_tags  [NNP, POS, NN, MD, VB, TO, VB, IN, PRP, VBP, D...   \n","\n","                                                          8   \n","tokens    [withdrawing, Elizabeth, Lol, multi-national, ...  \\\n","ud_tags   [AUX, PRON, VERB, PRON, VERB, PART, VERB, ADJ,...   \n","ptb_tags           [VBP, PRP, VB, PRP, VBP, TO, VB, JJR, .]   \n","\n","                                                          9  ...   \n","tokens    [rift, Pacheco, 2545, 973-3634, Selah, JR, Ric...  ...  \\\n","ud_tags   [CCONJ, PART, VERB, DET, NOUN, ADP, DET, ADJ, ...  ...   \n","ptb_tags  [CC, TO, VB, DT, NN, IN, DT, JJ, NN, VBZ, TO, ...  ...   \n","\n","                                                      12533   \n","tokens    [padded, slightly, fill, gunpowder, _, ingredi...  \\\n","ud_tags   [PRON, AUX, AUX, ADJ, CCONJ, PRON, AUX, PART, ...   \n","ptb_tags  [DT, MD, VB, JJ, CC, PRP, VBZ, RB, VB, ,, MD, ...   \n","\n","                                                      12534   \n","tokens    [arrogant, Iris, Qaeda, arrogant, abt, arrogan...  \\\n","ud_tags   [PUNCT, X, PUNCT, PUNCT, VERB, PUNCT, X, PUNCT...   \n","ptb_tags  [``, FW, ., '', VBZ, ``, FW, '', ,, CC, ``, PR...   \n","\n","                                                      12535   \n","tokens    [rift, clan, alt.animals.horses.breeding, perc...  \\\n","ud_tags   [CCONJ, SCONJ, NOUN, AUX, DET, NOUN, PUNCT, PR...   \n","ptb_tags  [CC, IN, NN, VBZ, DT, NN, ,, NN, MD, VB, IN, D...   \n","\n","                                     12536   \n","tokens    [Oslo, clash, newsletter, della]  \\\n","ud_tags           [ADJ, PUNCT, NOUN, NOUN]   \n","ptb_tags               [JJ, HYPH, NN, NNS]   \n","\n","                                        12537   \n","tokens    [FAQ, Load, 973-3634, anyway, Cafe]  \\\n","ud_tags        [INTJ, VERB, DET, NOUN, PUNCT]   \n","ptb_tags                  [UH, VB, DT, NN, .]   \n","\n","                                                      12538   \n","tokens    [neoconservative, begin, school, conservation,...  \\\n","ud_tags   [X, PUNCT, ADP, NOUN, NUM, PUNCT, NOUN, PUNCT,...   \n","ptb_tags  [LS, ., IN, NN, CD, ,, NN, -LRB-, NN, -RRB-, M...   \n","\n","                                                      12539   \n","tokens    [southwestern, Horizon, Windsor, Game, comes, ...  \\\n","ud_tags   [ADV, DET, ADJ, PROPN, NOUN, NOUN, PUNCT, INTJ...   \n","ptb_tags                [RB, DT, JJ, NNP, NN, NN, ,, UH, .]   \n","\n","                                                      12540   \n","tokens    [NOTE, 01/13/2001, innovations, Traders, permi...  \\\n","ud_tags   [CCONJ, DET, NOUN, PRON, VERB, X, NOUN, PRON, ...   \n","ptb_tags  [CC, DT, NN, PRP, VBP, GW, NN, PRP, MD, VB, IN...   \n","\n","                                                      12541   \n","tokens    [pyrimidal, Ordinarily, 973-3634, grandeur, un...  \\\n","ud_tags   [ADV, AUX, DET, NOUN, SCONJ, VERB, ADV, PUNCT,...   \n","ptb_tags           [RB, VBZ, DT, NN, IN, VBG, RB, ,, NN, .]   \n","\n","                                                      12542  \n","tokens    [clan, quit, MORALITY, installed, quit, 01:09,...  \n","ud_tags   [SCONJ, PRON, VERB, PUNCT, PRON, AUX, PART, VE...  \n","ptb_tags            [IN, PRP, VBP, ,, PRP, VBP, RB, VBG, .]  \n","\n","[3 rows x 12543 columns]"]},"execution_count":360,"metadata":{},"output_type":"execute_result"}],"source":["train_set_df = pd.DataFrame(train_set)\n","train_set_df"]},{"cell_type":"code","execution_count":361,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:21.257544Z","iopub.status.busy":"2023-05-03T09:43:21.256747Z","iopub.status.idle":"2023-05-03T09:43:21.275551Z","shell.execute_reply":"2023-05-03T09:43:21.274316Z","shell.execute_reply.started":"2023-05-03T09:43:21.257504Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(0                                         [Islam, Skilled]\n"," 1                           [origination, Great, attorney]\n"," 2        [Figuratively, Others, fill, intents, installe...\n"," 3        [Discovery, alarms, bag, dishonest, puff, arro...\n"," 4        [read, 202.456.1111, versions, airliner, uplan...\n","                                ...                        \n"," 12538    [neoconservative, begin, school, conservation,...\n"," 12539    [southwestern, Horizon, Windsor, Game, comes, ...\n"," 12540    [NOTE, 01/13/2001, innovations, Traders, permi...\n"," 12541    [pyrimidal, Ordinarily, 973-3634, grandeur, un...\n"," 12542    [clan, quit, MORALITY, installed, quit, 01:09,...\n"," Name: tokens, Length: 12543, dtype: object,\n"," 0                                           [PROPN, PROPN]\n"," 1                                         [NUM, NUM, NOUN]\n"," 2        [NOUN, AUX, AUX, VERB, PUNCT, ADP, DET, NOUN, ...\n"," 3        [PRON, NOUN, PART, NOUN, VERB, PUNCT, NOUN, VE...\n"," 4        [PRON, AUX, VERB, DET, NOUN, NOUN, ADP, SCONJ,...\n","                                ...                        \n"," 12538    [X, PUNCT, ADP, NOUN, NUM, PUNCT, NOUN, PUNCT,...\n"," 12539    [ADV, DET, ADJ, PROPN, NOUN, NOUN, PUNCT, INTJ...\n"," 12540    [CCONJ, DET, NOUN, PRON, VERB, X, NOUN, PRON, ...\n"," 12541    [ADV, AUX, DET, NOUN, SCONJ, VERB, ADV, PUNCT,...\n"," 12542    [SCONJ, PRON, VERB, PUNCT, PRON, AUX, PART, VE...\n"," Name: ud_tags, Length: 12543, dtype: object,\n"," 0                                               [NNP, NNP]\n"," 1                                             [CD, CD, NN]\n"," 2        [NN, MD, VB, VBN, ,, IN, DT, NN, IN, DT, VBN, ...\n"," 3        [PRP$, NN, POS, NN, VBZ, ``, NN, VBN, IN, JJ, ...\n"," 4        [PRP, MD, VB, DT, NN, NN, IN, IN, VBG, DT, NN,...\n","                                ...                        \n"," 12538    [LS, ., IN, NN, CD, ,, NN, -LRB-, NN, -RRB-, M...\n"," 12539                  [RB, DT, JJ, NNP, NN, NN, ,, UH, .]\n"," 12540    [CC, DT, NN, PRP, VBP, GW, NN, PRP, MD, VB, IN...\n"," 12541             [RB, VBZ, DT, NN, IN, VBG, RB, ,, NN, .]\n"," 12542              [IN, PRP, VBP, ,, PRP, VBP, RB, VBG, .]\n"," Name: ptb_tags, Length: 12543, dtype: object)"]},"execution_count":361,"metadata":{},"output_type":"execute_result"}],"source":["pd_tokens = train_set_df.loc[\"tokens\"]\n","pd_ud_tags = train_set_df.loc[\"ud_tags\"]\n","pd_ptb_tags = train_set_df.loc[\"ptb_tags\"]\n","\n","pd_tokens, pd_ud_tags, pd_ptb_tags"]},{"cell_type":"code","execution_count":362,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:21.278027Z","iopub.status.busy":"2023-05-03T09:43:21.277027Z","iopub.status.idle":"2023-05-03T09:43:21.286011Z","shell.execute_reply":"2023-05-03T09:43:21.284640Z","shell.execute_reply.started":"2023-05-03T09:43:21.277979Z"},"trusted":true},"outputs":[],"source":["tokens = np.array(pd_tokens)\n","ud_tags = np.array(pd_ud_tags)\n","ptb_tags = np.array(pd_ptb_tags)"]},{"cell_type":"code","execution_count":363,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:21.293105Z","iopub.status.busy":"2023-05-03T09:43:21.292290Z","iopub.status.idle":"2023-05-03T09:43:35.480230Z","shell.execute_reply":"2023-05-03T09:43:35.478725Z","shell.execute_reply.started":"2023-05-03T09:43:21.293034Z"},"trusted":true},"outputs":[{"data":{"text/plain":["204605"]},"execution_count":363,"metadata":{},"output_type":"execute_result"}],"source":["tokens\n","number_of_tokens = sum(tokens, [])\n","len(number_of_tokens)"]},{"cell_type":"code","execution_count":364,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:35.482987Z","iopub.status.busy":"2023-05-03T09:43:35.481854Z","iopub.status.idle":"2023-05-03T09:43:35.839767Z","shell.execute_reply":"2023-05-03T09:43:35.838340Z","shell.execute_reply.started":"2023-05-03T09:43:35.482933Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["샘플의 최대 길이 : 159\n","샘플의 평균 길이 : 16.312286\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt \n","\n","print('샘플의 최대 길이 : %d' % max(len(l) for l in tokens))\n","print('샘플의 평균 길이 : %f' % (sum(map(len, tokens))/len(tokens)))\n","plt.hist([len(s) for s in tokens], bins=50)\n","plt.xlabel('length of samples')\n","plt.ylabel('number of samples')\n","plt.show()"]},{"cell_type":"code","execution_count":365,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:35.841950Z","iopub.status.busy":"2023-05-03T09:43:35.841582Z","iopub.status.idle":"2023-05-03T09:43:35.923443Z","shell.execute_reply":"2023-05-03T09:43:35.922274Z","shell.execute_reply.started":"2023-05-03T09:43:35.841903Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(20, 20, 20)"]},"execution_count":365,"metadata":{},"output_type":"execute_result"}],"source":["max_words = 20 # 최대 단어 개수     # 문장 길이\n","\n","# 배열의 각 요소에서 20개의 단어만 선택하는 함수\n","def select_words(arr):\n","    return [word for word in arr[:max_words]]\n","\n","# 배열의 각 요소에서 20개의 단어만 선택하는 코드\n","new_tokens = np.array([select_words(arr) if len(arr) > max_words else arr for arr in tokens], dtype=object)\n","new_ud_tags = np.array([select_words(arr) if len(arr) > max_words else arr for arr in ud_tags], dtype=object)\n","new_ptb_tags = np.array([select_words(arr) if len(arr) > max_words else arr for arr in ptb_tags], dtype=object)\n","\n","new_tokens_max_len = max(len(lst) for lst in new_tokens)      # 가장 긴 리스트의 길이\n","new_ud_tags_max_len = max(len(lst) for lst in new_ud_tags)      # 가장 긴 리스트의 길이\n","new_ptb_tags_max_len = max(len(lst) for lst in new_ptb_tags)      # 가장 긴 리스트의 길이\n","\n","new_tokens_max_len, new_ud_tags_max_len, new_ptb_tags_max_len\n"]},{"cell_type":"code","execution_count":366,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:35.925072Z","iopub.status.busy":"2023-05-03T09:43:35.924727Z","iopub.status.idle":"2023-05-03T09:43:36.120060Z","shell.execute_reply":"2023-05-03T09:43:36.118623Z","shell.execute_reply.started":"2023-05-03T09:43:35.925029Z"},"trusted":true},"outputs":[{"data":{"text/plain":["([['Islam',\n","   'Skilled',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]'],\n","  ['origination',\n","   'Great',\n","   'attorney',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]',\n","   '[PAD]']],\n"," (12543, 20))"]},"execution_count":366,"metadata":{},"output_type":"execute_result"}],"source":["max_len = 20\n","pad_token = '[PAD]'\n","new_data_padded = []\n","for sentence in new_tokens:\n","    if len(sentence) < max_len:\n","        num_padding = max_len - len(sentence)\n","        sentence = sentence + [pad_token] * num_padding     # sentence = [pad_token] * num_padding + sentence\n","    else:\n","        sentence = sentence[:max_len]\n","    new_data_padded.append(sentence)\n","    \n","new_data_padded[0:2], np.array(new_data_padded).shape "]},{"cell_type":"code","execution_count":367,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:36.122709Z","iopub.status.busy":"2023-05-03T09:43:36.121489Z","iopub.status.idle":"2023-05-03T09:43:36.130584Z","shell.execute_reply":"2023-05-03T09:43:36.129391Z","shell.execute_reply.started":"2023-05-03T09:43:36.122668Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[['Islam',\n","  'Skilled',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]'],\n"," ['origination',\n","  'Great',\n","  'attorney',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]',\n","  '[PAD]']]"]},"execution_count":367,"metadata":{},"output_type":"execute_result"}],"source":["train_data = new_data_padded\n","train_data[0:2]#, train_data.shape\n","\n","#train_data = train_data[0:2]\n","\n","#train_data"]},{"cell_type":"code","execution_count":368,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:36.132285Z","iopub.status.busy":"2023-05-03T09:43:36.131943Z","iopub.status.idle":"2023-05-03T09:43:36.303389Z","shell.execute_reply":"2023-05-03T09:43:36.301927Z","shell.execute_reply.started":"2023-05-03T09:43:36.132253Z"},"trusted":true},"outputs":[],"source":["dic = word_dic_and_embedding"]},{"cell_type":"code","execution_count":369,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:36.306231Z","iopub.status.busy":"2023-05-03T09:43:36.305508Z","iopub.status.idle":"2023-05-03T09:43:36.330169Z","shell.execute_reply":"2023-05-03T09:43:36.328704Z","shell.execute_reply.started":"2023-05-03T09:43:36.306184Z"},"trusted":true},"outputs":[],"source":["idx = list(range(0,len(dic)))\n","\n","dic_list = list(dic.keys())\n","\n","id_to_word = dict(zip(idx, dic_list))\n","\n","word_to_id = {i: w for w, i in id_to_word.items()}\n","#word_to_id"]},{"cell_type":"code","execution_count":370,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:36.332424Z","iopub.status.busy":"2023-05-03T09:43:36.331707Z","iopub.status.idle":"2023-05-03T09:43:36.342658Z","shell.execute_reply":"2023-05-03T09:43:36.341319Z","shell.execute_reply.started":"2023-05-03T09:43:36.332378Z"},"trusted":true},"outputs":[{"data":{"text/plain":["19674"]},"execution_count":370,"metadata":{},"output_type":"execute_result"}],"source":["len(dic)"]},{"cell_type":"code","execution_count":371,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:36.345575Z","iopub.status.busy":"2023-05-03T09:43:36.344700Z","iopub.status.idle":"2023-05-03T09:43:36.357021Z","shell.execute_reply":"2023-05-03T09:43:36.355847Z","shell.execute_reply.started":"2023-05-03T09:43:36.345521Z"},"trusted":true},"outputs":[{"data":{"text/plain":["12543"]},"execution_count":371,"metadata":{},"output_type":"execute_result"}],"source":["len(train_data)"]},{"cell_type":"markdown","metadata":{},"source":["# Train_dataset(Word to idx(int))"]},{"cell_type":"code","execution_count":372,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:36.359919Z","iopub.status.busy":"2023-05-03T09:43:36.358453Z","iopub.status.idle":"2023-05-03T09:43:36.511554Z","shell.execute_reply":"2023-05-03T09:43:36.510279Z","shell.execute_reply.started":"2023-05-03T09:43:36.359873Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[15658,  5694,     0, ...,     0,     0,     0],\n","       [ 1121,  9452, 17518, ...,     0,     0,     0],\n","       [ 2336,  8900,   167, ..., 19150,  2075,  2993],\n","       ...,\n","       [12693, 10076,  3240, ...,  6595,  5776,  5658],\n","       [18279,  7036, 13093, ...,     0,     0,     0],\n","       [ 2589,  2971,   484, ...,     0,     0,     0]])"]},"execution_count":372,"metadata":{},"output_type":"execute_result"}],"source":["# 일련번호 데이터\n","train_inputs = []\n","for s in train_data:                                 ##### 문장별 반복\n","    #print(s)\n","    #print(\"print SSSSS\")\n","    row= []\n","    for w in s:\n","        #print(w)\n","        #print(\"WWWWWWWWW\")\n","        if w in word_to_id:\n","            row.append(word_to_id[w])\n","            #print(row)\n","        else:\n","            row.append(word_to_id['[UNK]'])\n","    #print(row)                                    ##### 번호 나열\n","    train_inputs.append(row)\n","train_inputs = np.array(train_inputs)\n","\n","train_inputs, train_inputs.shape\n","\n","X_train = train_inputs\n","X_train"]},{"cell_type":"markdown","metadata":{},"source":["# Fipping token"]},{"cell_type":"code","execution_count":373,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:36.513889Z","iopub.status.busy":"2023-05-03T09:43:36.512992Z","iopub.status.idle":"2023-05-03T09:43:36.865807Z","shell.execute_reply":"2023-05-03T09:43:36.864529Z","shell.execute_reply.started":"2023-05-03T09:43:36.513851Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(array([[15658,  5694,     0, ...,     0,     0,     0],\n","        [ 1121,  9452, 17518, ...,     0,     0,     0],\n","        [ 2336,  8900,   167, ..., 19150,  2075,  2993],\n","        ...,\n","        [12693, 10076,  3240, ...,  6595,  5776,  5658],\n","        [18279,  7036, 13093, ...,     0,     0,     0],\n","        [ 2589,  2971,   484, ...,     0,     0,     0]]),\n"," array([[ 5694, 15658,     0, ...,     0,     0,     0],\n","        [17518,  9452,  1121, ...,     0,     0,     0],\n","        [ 2993,  2075, 19150, ...,   167,  8900,  2336],\n","        ...,\n","        [ 5658,  5776,  6595, ...,  3240, 10076, 12693],\n","        [10295, 15932,  9143, ...,     0,     0,     0],\n","        [12879, 14059, 13293, ...,     0,     0,     0]]))"]},"execution_count":373,"metadata":{},"output_type":"execute_result"}],"source":["original_list = new_tokens\n","flipped_list = [lst[::-1] for lst in original_list]\n","filp_new_token = np.array(flipped_list, dtype=object)\n","filp_new_token\n","\n","max_len = 20\n","pad_token = '[PAD]'\n","new_data_padded = []\n","for sentence in filp_new_token:\n","    if len(sentence) < max_len:\n","        num_padding = max_len - len(sentence)\n","        sentence = sentence + [pad_token] * num_padding     # sentence = [pad_token] * num_padding + sentence\n","    else:\n","        sentence = sentence[:max_len]\n","    new_data_padded.append(sentence)\n","    \n","new_data_padded[0:2], np.array(new_data_padded).shape \n","\n","flip_train_data = new_data_padded\n","flip_train_data[0:2]#, train_data.shape\n","\n","# 일련번호 데이터\n","filp_train_inputs = []\n","for s in flip_train_data:                                 ##### 문장별 반복\n","    #print(s)\n","    #print(\"print SSSSS\")\n","    row= []\n","    for w in s:\n","        #print(w)\n","        #print(\"WWWWWWWWW\")\n","        if w in word_to_id:\n","            row.append(word_to_id[w])\n","            #print(row)\n","        else:\n","            row.append(word_to_id['[UNK]'])\n","    #print(row)                                    ##### 번호 나열\n","    filp_train_inputs.append(row)\n","filp_train_inputs = np.array(filp_train_inputs)\n","\n","filp_train_inputs, filp_train_inputs.shape\n","\n","X_train_flip = filp_train_inputs\n","X_train, X_train_flip\n"]},{"cell_type":"markdown","metadata":{},"source":["# Train_Lable"]},{"cell_type":"code","execution_count":374,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:36.868210Z","iopub.status.busy":"2023-05-03T09:43:36.867448Z","iopub.status.idle":"2023-05-03T09:43:36.877194Z","shell.execute_reply":"2023-05-03T09:43:36.875974Z","shell.execute_reply.started":"2023-05-03T09:43:36.868162Z"},"trusted":true},"outputs":[{"data":{"text/plain":["{'[PAD]': 0,\n"," 'ADP': 1,\n"," 'PROPN': 2,\n"," 'PART': 3,\n"," 'SYM': 4,\n"," 'PUNCT': 5,\n"," 'NOUN': 6,\n"," 'CCONJ': 7,\n"," 'AUX': 8,\n"," 'X': 9,\n"," 'ADJ': 10,\n"," 'ADV': 11,\n"," 'VERB': 12,\n"," 'SCONJ': 13,\n"," 'DET': 14,\n"," 'NUM': 15,\n"," 'INTJ': 16,\n"," 'PRON': 17}"]},"execution_count":374,"metadata":{},"output_type":"execute_result"}],"source":["label_dic = tgt.to_dict()[0]\n","\n","label_dic = dict((value, key) for key, value in label_dic.items())\n","\n","label_dic"]},{"cell_type":"code","execution_count":375,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:36.879397Z","iopub.status.busy":"2023-05-03T09:43:36.879002Z","iopub.status.idle":"2023-05-03T09:43:37.400244Z","shell.execute_reply":"2023-05-03T09:43:37.399078Z","shell.execute_reply.started":"2023-05-03T09:43:36.879363Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(array([[ 2,  2,  0, ...,  0,  0,  0],\n","        [15, 15,  6, ...,  0,  0,  0],\n","        [ 6,  8,  8, ...,  7,  6,  5],\n","        ...,\n","        [ 7, 14,  6, ...,  8,  3, 12],\n","        [11,  8, 14, ...,  0,  0,  0],\n","        [13, 17, 12, ...,  0,  0,  0]]),\n"," (12543, 20))"]},"execution_count":375,"metadata":{},"output_type":"execute_result"}],"source":["new_ud_tags\n","\n","max_len = 20\n","pad_token = '[PAD]'\n","new_ud_tags_padded = []\n","for sentence in new_ud_tags:\n","    if len(sentence) < max_len:\n","        num_padding = max_len - len(sentence)\n","        sentence = sentence + [pad_token] * num_padding     # sentence = [pad_token] * num_padding + sentence\n","    else:\n","        sentence = sentence[:max_len]\n","    new_ud_tags_padded.append(sentence)\n","    \n","new_ud_tags_padded[0:2], np.array(new_ud_tags_padded).shape \n","\n","\n","# 일련번호 데이터\n","label_inputs = []\n","for s in new_ud_tags_padded:                                 ##### 문장별 반복\n","    #print(s)\n","    #print(\"print SSSSS\")\n","    row= []\n","    for w in s:\n","        #print(w)\n","        #print(\"WWWWWWWWW\")\n","        if w in label_dic:\n","            row.append(label_dic[w])\n","            #print(row)\n","        else:\n","            row.append(label_dic['[UNK]'])\n","            #print(\"[UNK]\")\n","    #print(row)                                    ##### 번호 나열\n","    label_inputs.append(row)\n","label_inputs = np.array(label_inputs)\n","\n","label_inputs, label_inputs.shape\n","\n","y_train = label_inputs\n","y_train, y_train.shape"]},{"cell_type":"markdown","metadata":{},"source":["# TEST_FILE"]},{"cell_type":"code","execution_count":376,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:37.402934Z","iopub.status.busy":"2023-05-03T09:43:37.402012Z","iopub.status.idle":"2023-05-03T09:43:37.467715Z","shell.execute_reply":"2023-05-03T09:43:37.466454Z","shell.execute_reply.started":"2023-05-03T09:43:37.402886Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([[19253, 10317, 19673, ...,     0,     0,     0],\n","       [ 8385,   690,  8694, ...,     0,     0,     0],\n","       [ 7669,  1644,  9569, ...,     0,     0,     0],\n","       ...,\n","       [19673, 19037, 15175, ...,     0,     0,     0],\n","       [11126,  1862,  1270, ...,     0,     0,     0],\n","       [ 6245,  6177,  4049, ...,     0,     0,     0]])"]},"execution_count":376,"metadata":{},"output_type":"execute_result"}],"source":["test_set_df = pd.DataFrame(test_set)\n","pd_tokens = test_set_df.loc[\"tokens\"]\n","test_tokens = np.array(pd_tokens)   # #tokens = 6280 which is needed in kaggle\n","\n","max_words = max(len(lst) for lst in test_tokens) # 최대 단어 개수     # 문장 길이   # 65\n","\n","# 배열의 각 요소에서 20개의 단어만 선택하는 함수\n","def select_words(arr):\n","    return [word for word in arr[:max_words]]\n","\n","# 배열의 각 요소에서 20개의 단어만 선택하는 코드\n","test_new_tokens = np.array([select_words(arr) if len(arr) > max_words else arr for arr in test_tokens], dtype=object)\n","\n","new_tokens_max_len = max(len(lst) for lst in test_new_tokens)      # 가장 긴 리스트의 길이\n","\n","new_tokens_max_len\n","\n","tuple_data  = test_new_tokens.tolist()\n","tuple_data[0:3]\n","\n","max_len = max_words\n","pad_token = '[PAD]'\n","new_data_padded = []\n","for sentence in test_new_tokens:\n","    if len(sentence) < max_len:\n","        num_padding = max_len - len(sentence)\n","        sentence = sentence + [pad_token] * num_padding     # sentence = [pad_token] * num_padding + sentence\n","    else:\n","        sentence = sentence[:max_len]\n","    new_data_padded.append(sentence)\n","    \n","new_data_padded[0:2], np.array(new_data_padded).shape \n","\n","test_data = new_data_padded\n","test_data[0:2]#, train_data.shape\n","\n","\n","# 일련번호 데이터\n","test_inputs = []\n","for s in test_data:                                 ##### 문장별 반복\n","    #print(s)\n","    #print(\"print SSSSS\")\n","    row= []\n","    for w in s:\n","        #print(w)\n","        #print(\"WWWWWWWWW\")\n","        if w in word_to_id:\n","            row.append(word_to_id[w])\n","            #print(row)\n","        else:\n","            row.append(word_to_id['[UNK]'])\n","    #print(row)                                    ##### 번호 나열\n","    test_inputs.append(row)\n","test_inputs = np.array(test_inputs)\n","\n","test_inputs, test_inputs.shape\n","\n","X_test = test_inputs\n","X_test"]},{"cell_type":"markdown","metadata":{},"source":["# Flipping Test_Set"]},{"cell_type":"code","execution_count":377,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:37.470130Z","iopub.status.busy":"2023-05-03T09:43:37.469216Z","iopub.status.idle":"2023-05-03T09:43:37.512326Z","shell.execute_reply":"2023-05-03T09:43:37.511149Z","shell.execute_reply.started":"2023-05-03T09:43:37.470071Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(array([[19253, 10317, 19673, ...,     0,     0,     0],\n","        [ 8385,   690,  8694, ...,     0,     0,     0],\n","        [ 7669,  1644,  9569, ...,     0,     0,     0],\n","        ...,\n","        [19673, 19037, 15175, ...,     0,     0,     0],\n","        [11126,  1862,  1270, ...,     0,     0,     0],\n","        [ 6245,  6177,  4049, ...,     0,     0,     0]]),\n"," (500, 65),\n"," array([[12879,  2359, 19090, ...,     0,     0,     0],\n","        [12879,  8569,   167, ...,     0,     0,     0],\n","        [12879, 11121,  9967, ...,     0,     0,     0],\n","        ...,\n","        [12879, 15175, 19037, ...,     0,     0,     0],\n","        [ 8112,  4633, 19477, ...,     0,     0,     0],\n","        [11007, 12879,   636, ...,     0,     0,     0]]),\n"," (500, 65))"]},"execution_count":377,"metadata":{},"output_type":"execute_result"}],"source":["original_list = test_new_tokens\n","flipped_list = [lst[::-1] for lst in original_list]\n","filp_new_token = np.array(flipped_list, dtype=object)\n","filp_new_token\n","\n","max_len = max(len(lst) for lst in test_tokens) # 최대 단어 개수     # 문장 길이   # 65\n","pad_token = '[PAD]'\n","new_data_padded = []\n","for sentence in filp_new_token:\n","    if len(sentence) < max_len:\n","        num_padding = max_len - len(sentence)\n","        sentence = sentence + [pad_token] * num_padding     # sentence = [pad_token] * num_padding + sentence\n","    else:\n","        sentence = sentence[:max_len]\n","    new_data_padded.append(sentence)\n","    \n","new_data_padded[0:2], np.array(new_data_padded).shape \n","\n","flip_test_data = new_data_padded\n","flip_test_data[0:2]#, train_data.shape\n","\n","# 일련번호 데이터\n","filp_test_inputs = []\n","for s in flip_test_data:                                 ##### 문장별 반복\n","    #print(s)\n","    #print(\"print SSSSS\")\n","    row= []\n","    for w in s:\n","        #print(w)\n","        #print(\"WWWWWWWWW\")\n","        if w in word_to_id:\n","            row.append(word_to_id[w])\n","            #print(row)\n","        else:\n","            row.append(word_to_id['[UNK]'])\n","    #print(row)                                    ##### 번호 나열\n","    filp_test_inputs.append(row)\n","filp_test_inputs = np.array(filp_test_inputs)\n","\n","filp_test_inputs, filp_test_inputs.shape\n","\n","X_test_flip = filp_test_inputs\n","X_test, X_test.shape, X_test_flip, X_test_flip.shape"]},{"cell_type":"markdown","metadata":{},"source":["# Masking"]},{"cell_type":"code","execution_count":378,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:37.515211Z","iopub.status.busy":"2023-05-03T09:43:37.513929Z","iopub.status.idle":"2023-05-03T09:43:37.521758Z","shell.execute_reply":"2023-05-03T09:43:37.520641Z","shell.execute_reply.started":"2023-05-03T09:43:37.515169Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","train_mask : \n","\n"," [[ True  True False ... False False False]\n"," [ True  True  True ... False False False]\n"," [ True  True  True ...  True  True  True]\n"," ...\n"," [ True  True  True ...  True  True  True]\n"," [ True  True  True ... False False False]\n"," [ True  True  True ... False False False]] (12543, 20) \n","\n","test_mask : \n","\n"," [[ True  True  True ... False False False]\n"," [ True  True  True ... False False False]\n"," [ True  True  True ... False False False]\n"," ...\n"," [ True  True  True ... False False False]\n"," [ True  True  True ... False False False]\n"," [ True  True  True ... False False False]] (500, 65)\n"]}],"source":["train_mask = (X_train != 0)\n","test_mask = (X_test != 0)\n","print(\"\\ntrain_mask : \\n\\n\", train_mask, train_mask.shape, \"\\n\\ntest_mask : \\n\\n\", test_mask, test_mask.shape)"]},{"cell_type":"code","execution_count":379,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:37.523645Z","iopub.status.busy":"2023-05-03T09:43:37.523333Z","iopub.status.idle":"2023-05-03T09:43:37.532840Z","shell.execute_reply":"2023-05-03T09:43:37.531882Z","shell.execute_reply.started":"2023-05-03T09:43:37.523616Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cuda device in training\n"]}],"source":["import torch\n","\n","gpudevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using {gpudevice} device in training\")"]},{"cell_type":"code","execution_count":380,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:37.534890Z","iopub.status.busy":"2023-05-03T09:43:37.534008Z","iopub.status.idle":"2023-05-03T09:43:37.994606Z","shell.execute_reply":"2023-05-03T09:43:37.992607Z","shell.execute_reply.started":"2023-05-03T09:43:37.534855Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","         [-0.0088, -0.0130,  0.0066,  ...,  0.0050, -0.0007, -0.0054],\n","         [-0.0050, -0.0007, -0.0566,  ...,  0.0020, -0.0212,  0.0257],\n","         ...,\n","         [-0.0160,  0.0183, -0.0089,  ..., -0.0158, -0.0047,  0.0224],\n","         [ 0.0310,  0.0254,  0.0145,  ...,  0.0157, -0.0244, -0.0231],\n","         [-0.0107,  0.0070,  0.0095,  ...,  0.0104, -0.0072, -0.0096]],\n","        device='cuda:0', dtype=torch.float64),\n"," torch.Size([19674, 300]))"]},"execution_count":380,"metadata":{},"output_type":"execute_result"}],"source":["emb = np.array(list(dic.values()))\n","emb = torch.as_tensor(emb).to(gpudevice)\n","emb, emb.shape"]},{"cell_type":"markdown","metadata":{},"source":["# Assemble_data"]},{"cell_type":"code","execution_count":381,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:38.001613Z","iopub.status.busy":"2023-05-03T09:43:38.001237Z","iopub.status.idle":"2023-05-03T09:43:38.015813Z","shell.execute_reply":"2023-05-03T09:43:38.014573Z","shell.execute_reply.started":"2023-05-03T09:43:38.001578Z"},"trusted":true},"outputs":[],"source":["onehot_metrix = np.eye(len(label_dic))  \n","onehot_metrix.shape\n","label_onehots = onehot_metrix[y_train]\n","label_onehots.shape\n","y_train = label_onehots"]},{"cell_type":"code","execution_count":382,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:38.018140Z","iopub.status.busy":"2023-05-03T09:43:38.017647Z","iopub.status.idle":"2023-05-03T09:43:38.026151Z","shell.execute_reply":"2023-05-03T09:43:38.024984Z","shell.execute_reply.started":"2023-05-03T09:43:38.018067Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(12543, 20, 18)"]},"execution_count":382,"metadata":{},"output_type":"execute_result"}],"source":["y_train.shape  # one-hot"]},{"cell_type":"code","execution_count":383,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:38.028720Z","iopub.status.busy":"2023-05-03T09:43:38.027761Z","iopub.status.idle":"2023-05-03T09:43:38.036193Z","shell.execute_reply":"2023-05-03T09:43:38.034879Z","shell.execute_reply.started":"2023-05-03T09:43:38.028682Z"},"trusted":true},"outputs":[{"data":{"text/plain":["((12543, 20),\n"," (12543, 20),\n"," (12543, 20, 18),\n"," (500, 65),\n"," (500, 65),\n"," (12543, 20),\n"," (500, 65))"]},"execution_count":383,"metadata":{},"output_type":"execute_result"}],"source":["X_train.shape, X_train_flip.shape, y_train.shape, X_test.shape, X_test_flip.shape, train_mask.shape, test_mask.shape"]},{"cell_type":"markdown","metadata":{},"source":["# demo"]},{"cell_type":"markdown","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-05-01T13:52:37.977191Z","iopub.status.busy":"2023-05-01T13:52:37.976486Z","iopub.status.idle":"2023-05-01T13:52:55.103340Z","shell.execute_reply":"2023-05-01T13:52:55.101882Z","shell.execute_reply.started":"2023-05-01T13:52:37.977153Z"}},"source":["from sklearn.model_selection import train_test_split\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=.2, random_state=777)\n","\n","print('훈련 샘플 문장의 크기 : {}'.format(X_train.shape))\n","print('훈련 샘플 레이블의 크기 : {}'.format(y_train.shape))\n","print('테스트 샘플 문장의 크기 : {}'.format(X_test.shape))\n","print('테스트 샘플 레이블의 크기 : {}'.format(y_val.shape))\n","\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, LSTM, InputLayer, Bidirectional, TimeDistributed, Embedding\n","from tensorflow.keras.optimizers import Adam\n","\n","embedding_dim = 128\n","hidden_units = 128\n","vocab_size = len(dic)\n","tag_size = len(label_dic)\n","\n","model = Sequential()\n","model.add(Embedding(vocab_size, embedding_dim, mask_zero=True))\n","model.add(Bidirectional(LSTM(hidden_units, return_sequences=True)))\n","model.add(TimeDistributed(Dense(tag_size, activation=('softmax'))))\n","\n","model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n","model.fit(X_train, y_train, batch_size=128, epochs=2, validation_data=(X_val, y_val))\n","\n","prediction = model(X_test)\n","\n","prediction.shape\n","\n","X_test.shape, prediction.shape"]},{"cell_type":"code","execution_count":384,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:38.039486Z","iopub.status.busy":"2023-05-03T09:43:38.037594Z","iopub.status.idle":"2023-05-03T09:43:49.446296Z","shell.execute_reply":"2023-05-03T09:43:49.444801Z","shell.execute_reply.started":"2023-05-03T09:43:38.039438Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: torchsummary in c:\\users\\user\\anaconda3\\envs\\torchpro\\lib\\site-packages (1.5.1)\n"]}],"source":["!pip install torchsummary"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-05-02T10:38:31.159159Z","iopub.status.busy":"2023-05-02T10:38:31.158205Z","iopub.status.idle":"2023-05-02T10:38:31.200876Z","shell.execute_reply":"2023-05-02T10:38:31.199830Z","shell.execute_reply.started":"2023-05-02T10:38:31.159098Z"}},"source":["import torch.nn as nn\n","\n","class DeepBiRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_layers, output_size):\n","        super(DeepBiRNN, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        self.output_size = output_size\n","        \n","        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n","        self.fc = nn.Linear(hidden_size*2, output_size)\n","    \n","    def forward(self, x):\n","        # x shape: (batch_size, seq_len, input_size)\n","        out, _ = self.rnn(x)\n","        print(\"out.shape : \", out.shape)\n","        out = self.fc(out)\n","        # out shape: (batch_size, seq_len, output_size)\n","        return out\n","\n","# 모델 생성\n","input_size = 10\n","hidden_size = 32\n","num_layers = 3\n","output_size = 5\n","\n","model = DeepBiRNN(input_size, hidden_size, num_layers, output_size)\n","\n","# 입력 데이터 생성\n","batch_size = 4\n","seq_len = 10\n","input_data = torch.randn(batch_size, seq_len, input_size)\n","\n","# 모델 실행\n","output = model(input_data)\n","print(output)  # torch.Size([4, 10, 5])"]},{"cell_type":"code","execution_count":385,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","\n","class BidirectionalBatchRNNbacward(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):   # (300, 512, 128)\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.W_hh_f = nn.Parameter(torch.randn(hidden_size, hidden_size))   # (512, 512)\n","        self.W_xh_f = nn.Parameter(torch.randn(input_size, hidden_size))    # (300, 512)\n","        #self.W_hy_f = nn.Parameter(torch.randn(hidden_size, output_size))   # (512, 6)\n","        self.bias_h_f = nn.Parameter(torch.randn(hidden_size))              # (512)\n","        \n","        self.W_hh_b = nn.Parameter(torch.randn(hidden_size, hidden_size))   # (512, 512)\n","        self.W_xh_b = nn.Parameter(torch.randn(input_size, hidden_size))    # (300, 512)\n","        #self.W_hy_b = nn.Parameter(torch.randn(hidden_size, output_size))   # (512, 6)\n","        self.bias_h_b = nn.Parameter(torch.randn(hidden_size))              # (512)\n","        \n","        self.W_hy = nn.Parameter(torch.randn(hidden_size, output_size))   # (512, 128)     ###### due to concat\n","        #print(\"input_size, hidden_size, output_size : \",input_size, hidden_size, output_size)   # (300,512,512)\n","        #print(\"self.W_hy self.W_hy: \", self.W_hy.shape)   # (1024,512)\n","\n","\n","    def forward(self, x, h_f=None, h_b=None):\n","        batch_size, seq_len, input_size = x.size()  # batch_size를 추출합니다.   (256, 20, 300)\n","\n","        if h_f is None:\n","            h_f = torch.zeros(batch_size, self.hidden_size, device=x.device)   # \n","        if h_b is None:\n","            h_b = torch.zeros(batch_size, self.hidden_size, device=x.device)\n","        \n","        # Backward pass\n","        h_b_list = []  # (20,256,512)\n","        for t in reversed(range(seq_len)):   # reversed 19 to 0\n","            h_b = torch.tanh(torch.matmul(x[:, t, :], self.W_xh_b) + torch.matmul(h_b, self.W_hh_b) + self.bias_h_b)\n","            h_b_list.append(h_b)\n","        #print(\"h_b_list[0] : \", h_b_list[0])\n","        h_b_list.reverse()                 # 리스트 단위 맨처음을 뒤로 # 순서대로 정렬 x1 to x19\n","\n","        h_b = torch.stack(h_b_list)\n","        y_b = torch.matmul(h_b, self.W_hy)\n","        \n","        #print(\"self.W_hy : \", self.W_hy.shape)   # (1024, 512)\n","        #print(\"#########y##########\", y_b.shape)   # (256, 20, 512)\n","        #print(\"permute_hcat : \", h_cat.shape)    # (256, 20, 1024)\n","        \n","        return y_b, h_b\n","    \n","    def __repr__(self):\n","        return f\"BidirectionalBatchRNN(input_size={self.W_xh_f.shape[0]}, hidden_size={self.hidden_size}, output_size={self.W_hy.shape[1]})\""]},{"cell_type":"code","execution_count":387,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T09:43:49.449436Z","iopub.status.busy":"2023-05-03T09:43:49.449018Z","iopub.status.idle":"2023-05-03T11:51:47.124156Z","shell.execute_reply":"2023-05-03T11:51:47.122740Z","shell.execute_reply.started":"2023-05-03T09:43:49.449385Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Textclassifier(\n","  (rnn): DeepRNN(input_size=300, hidden_size=256, output_size=64, num_layers=3)\n","  (linear1): Linear(in_features=128, out_features=64, bias=True)\n","  (linear2): Linear(in_features=64, out_features=18, bias=True)\n","  (softmax): Softmax(dim=1)\n",")\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_5756\\1525037603.py:227: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  embedded = torch.tensor(self.emb[text], dtype = torch.float32)     # (batch_size,20,300)\n"]}],"source":["import torch\n","import torch.nn as nn\n","\n","class BidirectionalBatchRNNforward(nn.Module):\n","    def __init__(self, input_size, hidden_size, output_size):   # (300, 512, 128)\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.W_hh_f = nn.Parameter(torch.randn(hidden_size, hidden_size))   # (512, 512)\n","        self.W_xh_f = nn.Parameter(torch.randn(input_size, hidden_size))    # (300, 512)\n","        #self.W_hy_f = nn.Parameter(torch.randn(hidden_size, output_size))   # (512, 6)\n","        self.bias_h_f = nn.Parameter(torch.randn(hidden_size))              # (512)\n","        \n","        self.W_hh_b = nn.Parameter(torch.randn(hidden_size, hidden_size))   # (512, 512)\n","        self.W_xh_b = nn.Parameter(torch.randn(input_size, hidden_size))    # (300, 512)\n","        #self.W_hy_b = nn.Parameter(torch.randn(hidden_size, output_size))   # (512, 6)\n","        self.bias_h_b = nn.Parameter(torch.randn(hidden_size))              # (512)\n","        \n","        self.W_hy = nn.Parameter(torch.randn(hidden_size, output_size))   # (512, 128)     ###### due to concat\n","        #print(\"input_size, hidden_size, output_size : \",input_size, hidden_size, output_size)   # (300,512,512)\n","        #print(\"self.W_hy self.W_hy: \", self.W_hy.shape)   # (1024,512)\n","\n","\n","    def forward(self, x, h_f=None, h_b=None):\n","        batch_size, seq_len, input_size = x.size()  # batch_size를 추출합니다.   (256, 20, 300)\n","\n","        if h_f is None:\n","            h_f = torch.zeros(batch_size, self.hidden_size, device=x.device)   # \n","        if h_b is None:\n","            h_b = torch.zeros(batch_size, self.hidden_size, device=x.device)\n","        \n","        # Forward pass\n","        h_f_list = []   # (20,256,512)   # 256개의 샘플에서 각각에 대해 20개 length에 대한 vector\n","        for t in range(seq_len): \n","            #print(\"x : \", x.shape)            # torch.Size([256, 20, 300])\n","            #print(\"x[:, t, :] : \", x[:, t, :].shape)   # x[:, 0, :] :  torch.Size([256, 300]) # 모든 배치에 대해 t번째 단어 embedding \n","            #print(\"self.W_xh_f : \", self.W_xh_f.shape)  # torch.Size([300, 512])\n","            #print(\"h_f : \", h_f.shape)\n","            #print(\"self.W_hh_f : \", self.W_hh_f.shape)  # torch.Size([512, 512])\n","            #print(\"self.bias_h_f : \", self.bias_h_f.shape)\n","            h_f = torch.tanh(torch.matmul(x[:, t, :], self.W_xh_f) + torch.matmul(h_f, self.W_hh_f) + self.bias_h_f) # (256,512)    각 샘플의 t번째에 파라미터 학습\n","            #print(\"h_f : \", h_f)\n","            h_f_list.append(h_f)  \n","        #y_f = torch.matmul(h_f, self.W_hy_f) # 마지막 seqence에 대해서 결과 도출   (20,256,512) * (512,6)\n","        #print(\"y_f : \", y_f.shape)\n","        \n","        # # Backward pass\n","        # h_b_list = []  # (20,256,512)\n","        # for t in reversed(range(seq_len)):   # reversed 19 to 0\n","        #     h_b = torch.tanh(torch.matmul(x[:, t, :], self.W_xh_b) + torch.matmul(h_b, self.W_hh_b) + self.bias_h_b)\n","        #     h_b_list.append(h_b)\n","        # #print(\"h_b_list[0] : \", h_b_list[0])\n","        # h_b_list.reverse()                 # 리스트 단위 맨처음을 뒤로 # 순서대로 정렬 x1 to x19\n","        # #print(\"h_b_list_reversed[-1] : \", h_b_list[-1])\n","        #y_b = torch.matmul(h_b_list[-1], self.W_hy_b)      # many to one !!!!!!!\n","        #print(\"y_b : \", y_b.shape)\n","        #print(\"torch.stack(h_f_list) : \", torch.stack(h_f_list).shape)   # torch.Size([20, 256, 512])\n","        #print(\"torch.stack(h_b_list) : \", torch.stack(h_b_list).shape)   # torch.Size([20, 256, 512])\n","        \n","        \n","        # Concatenate forward and backward outputs\n","        #h_cat = torch.cat([torch.stack(h_f_list), torch.stack(h_b_list)], dim=2) # (batch_size, seq_len, 2*hidden_size) # torch.Size([256, 20, 1024]) concatenation based on dim = 2(256) \n","        #print(\"h_cat : \", h_cat.shape)     # h_cat :  torch.Size([20, 256, 1024])\n","        #y_cat = torch.cat([y_f, y_b], dim=1) # (batch_size, 2*output_size)\n","        #print(\"y_cat : \", y_cat.shape)\n","        \n","        #h_cat = h_cat.permute(1,0,2)              # (256, 20, 1024)\n","        \n","        #print(\"h_cat : \", h_cat.shape)\n","        #y = torch.matmul(h_cat, self.W_hy)     # (256,20,512)\n","        h_f = torch.stack(h_f_list)\n","        y_f = torch.matmul(h_f, self.W_hy)\n","        \n","        #print(\"self.W_hy : \", self.W_hy.shape)   # (1024, 512)\n","        #print(\"#########y##########\", y.shape)   # (256, 20, 512)\n","        #print(\"permute_hcat : \", h_cat.shape)    # (256, 20, 1024)\n","        \n","        return y_f, h_f\n","    \n","    def __repr__(self):\n","        return f\"BidirectionalBatchRNN(input_size={self.W_xh_f.shape[0]}, hidden_size={self.hidden_size}, output_size={self.W_hy.shape[1]})\"\n","\n","##########################################################################################################\n","\n","import torch\n","import torch.nn as nn\n","\n","class DeepRNN(nn.Module):\n","    \n","    def __init__(self, input_size, hidden_size, output_size, num_layers):   # (300, 512, 128, 3)\n","        super().__init__()\n","        self.hidden_size = hidden_size\n","        self.num_layers = num_layers\n","        \n","        # 첫 번째 BatchRNN 레이어\n","        self.batch_rnn1f = BidirectionalBatchRNNforward(input_size, hidden_size, hidden_size)   # (300, 512, 512) (input_size, hidden_size, hidden_size(output_size))\n","        # \n","        # 중간에 쌓을 BatchRNN 레이어들\n","        self.batch_rnnsf = nn.ModuleList([BidirectionalBatchRNNforward(hidden_size, hidden_size, 128) for _ in range(num_layers-2)]) # (128, 128, 128)   # (hidden_size,hidden_size,hidden_size)\n","        \n","        # 마지막 BatchRNN 레이어\n","        self.batch_rnn2f = BidirectionalBatchRNNforward(128, hidden_size, output_size)  # org = (hidden_size, hidden_size, output_size) (128, 128, 512)\n","\n","\n","        self.batch_rnn1b = BidirectionalBatchRNNbacward(input_size, hidden_size, hidden_size)   # (300, 512, 512) (input_size, hidden_size, hidden_size(output_size))\n","        # \n","        # 중간에 쌓을 BatchRNN 레이어들\n","        self.batch_rnnsb = nn.ModuleList([BidirectionalBatchRNNforward(hidden_size, hidden_size, 128) for _ in range(num_layers-2)])# (128, 128, 128)   # (hidden_size,hidden_size,hidden_size)\n","        \n","        # 마지막 BatchRNN 레이어\n","        self.batch_rnn2b = BidirectionalBatchRNNforward(128, hidden_size, output_size)  # org = (hidden_size, hidden_size, output_size) (128, 128, 512)\n","        \n","\n","\n","        self.layer_norm1 = nn.LayerNorm(hidden_size)  # hidden_size\n","        self.layer_norm2 = nn.LayerNorm(128)  # hidden_size\n","        self.layer_norm3 = nn.LayerNorm(output_size)\n","        \n","        \n","        \n","        \n","        \n","    def forward(self, x, h_f=None, h_b=None):\n","        batch_size, seq_len, input_size = x.size()\n","        \n","        # 첫 번째 BatchRNN 레이어를 통과한 결과를 입력으로 사용합니다.\n","        yf, hf = self.batch_rnn1f(x, h_f)   # y = (256,20,512)\n","        #print(\"batch_rnn1_yyyyy : \", y.shape)\n","        yf = self.layer_norm1(yf)\n","        \n","        # 중간에 쌓은 BatchRNN 레이어를 차례대로 통과시킵니다.\n","        for batch_rnnf in self.batch_rnnsf:\n","            yf, hf = batch_rnnf(yf, h_f)\n","            #print(\"batch_rnn2_yyyyy : \", y.shape)\n","            yf = self.layer_norm2(yf)\n","        \n","        # 마지막 BatchRNN 레이어를 통과시킨 결과를 반환합니다.\n","        yf, hf = self.batch_rnn2f(yf, h_f)\n","        #print(\"batch_rnn3_yyyyy : \", y.shape)\n","        yf = self.layer_norm3(yf)\n","\n","#######################################################################\n","\n","        yb, hb = self.batch_rnn1b(x, h_b)   # y = (256,20,512)\n","        #print(\"batch_rnn1_yyyyy : \", y.shape)\n","        yb = self.layer_norm1(yb)\n","        \n","        # 중간에 쌓은 BatchRNN 레이어를 차례대로 통과시킵니다.\n","        for batch_rnnb in self.batch_rnnsb:\n","            yb, hb = batch_rnnb(yb, h_b)\n","            #print(\"batch_rnn2_yyyyy : \", y.shape)\n","            yb = self.layer_norm2(yb)\n","        \n","        # 마지막 BatchRNN 레이어를 통과시킨 결과를 반환합니다.\n","        yb, hb = self.batch_rnn2b(yb, h_b)\n","        #print(\"batch_rnn3_yyyyy : \", y.shape)\n","        yb = self.layer_norm3(yb)\n","\n","        #print(\"aaaaaaaaaaaaaaaaaaaaa:\",yf.shape,yb.shape)\n","\n","        y = torch.cat([yf, yb], dim=2) # (batch_size, 2*output_size)\n","\n","        #print(\"catyyyyy : \", y.shape)\n","\n","        y = y.permute(1,0,2)\n","\n","        #print(\"catyyyyy : \", y.shape)        \n","\n","        return y\n","    \n","    def __repr__(self):\n","        return f\"DeepRNN(input_size={self.batch_rnn1b.W_xh_f.shape[0]}, hidden_size={self.hidden_size}, output_size={self.batch_rnn2b.W_hy.shape[1]}, num_layers={self.num_layers})\"\n","\n","##########################################################################################################\n","    \n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torch.utils.data as data_utils\n","import numpy as np\n","from torchsummary import summary\n","\n","\n","batch_size = 256 # 256, 12543\n","\n","# 데이터를 Tensor로 변환\n","X_tensor = torch.tensor(X_train, dtype=torch.long).to(gpudevice)\n","y_tensor = torch.tensor(y_train, dtype=torch.long).to(gpudevice)\n","\n","# 데이터를 train set과 validation set으로 나눔\n","n_samples = X_train.shape[0]\n","val_size = int(0.2 * n_samples)  # 20%를 validation set으로 사용\n","train_size = n_samples - val_size\n","\n","train_indices, val_indices = np.split(np.arange(n_samples), [train_size])\n","\n","train_data = data_utils.TensorDataset(X_tensor[train_indices], y_tensor[train_indices])\n","val_data = data_utils.TensorDataset(X_tensor[val_indices], y_tensor[val_indices])\n","\n","trainloader = data_utils.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n","val_loader = data_utils.DataLoader(val_data, batch_size=batch_size, shuffle=False)\n","\n","\n","\n","# 모델 구현\n","class Textclassifier(nn.Module):\n","                        \n","    def __init__(self, input_size, hidden_size, output_size, num_layers, pre_trained): #pre_trained : torch.Size([9225, 300])\n","        super().__init__()\n","        #self.emb = create_emb_layer(pre_trained, False)  \n","        self.emb = pre_trained\n","        self.rnn = DeepRNN(input_size, hidden_size, output_size, num_layers)\n","        #self.dropout = nn.Dropout(p=0.2)\n","        #self.layer_norm = nn.LayerNorm(output_size)\n","        #self.flatten = nn.Flatten(start_dim=1)\n","        #self.fc = nn.Linear(output_size*20, 6)\n","        self.linear1 = nn.Linear(128, 64)\n","        self.linear2 = nn.Linear(64, 18)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","\n","\n","    def forward(self, text):\n","\n","        #print(\"text : \", text.shape)\n","\n","        embedded = torch.tensor(self.emb[text], dtype = torch.float32)     # (batch_size,20,300)\n","\n","        #print(\"embedded : \", embedded.shape)\n","\n","        y = self.rnn(embedded)#, h0)#, self.zero_state)\n","\n","        #print(\"yuyyyyyyyyyyyyyyyyyy : \",y.shape)\n","        \n","        #print(\"result_y : \", y, y.shape)\n","        #y = self.dropout(y)\n","\n","        #print(\"y : \", y.shape)\n","\n","        #norm = self.layer_norm(y)\n","\n","        #flatten = self.flatten(y)\n","        #print(\"flatten : \", flatten.shape)\n","\n","\n","        #fc_output = self.fc(flatten)\n","        #print(\"fc_output : \", fc_output.shape)\n","\n","        #print(\"fc_output : \", fc_output.shape)\n","        \n","        y = self.linear1(y)\n","        y = self.linear2(y)\n","        \n","        #print(\"linear_y : \", y.shape)\n","\n","        softmax_output = self.softmax(y)\n","        #print(\"softmax_output : \", softmax_output)\n","\n","        #print(\"softmax_output : \", softmax_output.shape)\n","\n","        #nn.utils.clip_grad_norm_(self.parameters(), max_norm=1.0)\n","\n","        return softmax_output\n","\n","                                   \n","                                   \n","\n","model = Textclassifier(input_size = 300, hidden_size = 256, output_size= 64, num_layers = 3, pre_trained = emb).to(gpudevice)  ## emb is embedding vector\n","#print(model.state_dict())     ### 초기 가중치 확인\n","\n","print(model)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001, betas=(0.9, 0.999))\n","\n","##########################################################################################################\n","\n","num_epochs = 50\n","\n","for epoch in range(num_epochs):\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        inputs, labels = data\n","        \n","        #print(\"inputs.shape : \", inputs,inputs.shape)   # (batch size, embedding_size) \n","        #print(\"labels.shape : \", labels,labels.shape)\n","\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        \n","        #print(\"outputs : \", outputs, outputs.shape)\n","        #print(\"labels : \", labels, labels.shape)\n","        \n","        loss = criterion(outputs.float(), labels.float())\n","        loss.backward()\n","\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","\n","\n","    # Calculate accuracy on validation set\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in val_loader:\n","            inputs, labels = data\n","            \n","            #print(\"val-inputs.shape : \", inputs.shape)   # (batch size, embedding_size) \n","            #print(\"val-labels.shape : \", labels.shape)\n","            \n","            outputs = model(inputs).to(gpudevice)\n","\n","            #print(\"outputs : \", outputs, outputs.shape)\n","            # print(\"labels : \", labels, labels.shape)\n","            \n","            \n","            \n","            _, predicted = torch.max(outputs, 2)\n","            _, labels = torch.max(labels, 2)\n","\n","            #print(\"predicted : \", predicted, predicted.shape)\n","\n","\n","            \n","            #print(\"predicted : \", predicted, predicted.shape)\n","            #print(\"labels : \", labels, labels.shape)\n","            \n","\n","            total += labels.size(0) * labels.size(1)\n","            correct += (predicted == labels).sum().item()\n","        # print(\"predicted : \", predicted, predicted.shape)\n","        # print(\"labels : \", labels, labels.shape)\n","\n","    accuracy = 100 * correct / total\n","\n","    print('[%d] loss: %.3f, accuracy: %.3f%%' % (epoch + 1, running_loss, accuracy))\n","    #for name, param in model.named_parameters():\n","    #    if param.requires_grad:\n","    #        print(name, param.data)\n","    running_loss = 0.0\n","    \n","print('Finished Training')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T11:51:47.126166Z","iopub.status.busy":"2023-05-03T11:51:47.125774Z","iopub.status.idle":"2023-05-03T11:51:49.920111Z","shell.execute_reply":"2023-05-03T11:51:49.918904Z","shell.execute_reply.started":"2023-05-03T11:51:47.126125Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["aaaaaaaaaaaaaaaaaaaaa: torch.Size([65, 500, 64]) torch.Size([65, 500, 64])\n","catyyyyy :  torch.Size([65, 500, 128])\n","catyyyyy :  torch.Size([500, 65, 128])\n","softmax_output :  torch.Size([500, 65, 18])\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_5756\\2935845282.py:227: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  embedded = torch.tensor(self.emb[text], dtype = torch.float32)     # (batch_size,20,300)\n"]},{"data":{"text/plain":["tensor([[0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0],\n","        [0, 0, 0,  ..., 0, 0, 0]], device='cuda:0')"]},"execution_count":171,"metadata":{},"output_type":"execute_result"}],"source":["X_test_tensor = torch.tensor(X_test, dtype=torch.long).to(gpudevice)\n","with torch.no_grad():\n","    output = model(X_test_tensor)\n","    _, predicted_labels = torch.max(output, 2)\n","    \n","predicted_labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T11:51:49.921884Z","iopub.status.busy":"2023-05-03T11:51:49.921460Z","iopub.status.idle":"2023-05-03T11:51:49.929469Z","shell.execute_reply":"2023-05-03T11:51:49.928213Z","shell.execute_reply.started":"2023-05-03T11:51:49.921850Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([500, 65])"]},"execution_count":172,"metadata":{},"output_type":"execute_result"}],"source":["predicted_labels.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T11:51:49.931709Z","iopub.status.busy":"2023-05-03T11:51:49.931361Z","iopub.status.idle":"2023-05-03T11:51:49.944857Z","shell.execute_reply":"2023-05-03T11:51:49.943547Z","shell.execute_reply.started":"2023-05-03T11:51:49.931675Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([0, 0, 0,  ..., 0, 0, 0], device='cuda:0')"]},"execution_count":173,"metadata":{},"output_type":"execute_result"}],"source":["pos = predicted_labels[test_mask]\n","pos"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T11:51:49.946963Z","iopub.status.busy":"2023-05-03T11:51:49.946584Z","iopub.status.idle":"2023-05-03T11:51:49.953146Z","shell.execute_reply":"2023-05-03T11:51:49.951860Z","shell.execute_reply.started":"2023-05-03T11:51:49.946921Z"},"trusted":true},"outputs":[],"source":["predicted_labels = pos"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-05-03T11:51:49.955457Z","iopub.status.busy":"2023-05-03T11:51:49.954996Z","iopub.status.idle":"2023-05-03T11:51:49.992838Z","shell.execute_reply":"2023-05-03T11:51:49.991303Z","shell.execute_reply.started":"2023-05-03T11:51:49.955421Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>S0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>S1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>S2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>S3</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>S4</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6275</th>\n","      <td>S6275</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6276</th>\n","      <td>S6276</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6277</th>\n","      <td>S6277</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6278</th>\n","      <td>S6278</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>6279</th>\n","      <td>S6279</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>6280 rows × 2 columns</p>\n","</div>"],"text/plain":["         ID  label\n","0        S0      0\n","1        S1      0\n","2        S2      0\n","3        S3      0\n","4        S4      0\n","...     ...    ...\n","6275  S6275      0\n","6276  S6276      0\n","6277  S6277      0\n","6278  S6278      0\n","6279  S6279      0\n","\n","[6280 rows x 2 columns]"]},"execution_count":175,"metadata":{},"output_type":"execute_result"}],"source":["index_list = []\n","for i in range(0,len(predicted_labels)):\n","    index_list.append(f\"S{i}\")\n","    \n","prediction = pd.DataFrame(columns=['ID', 'label'])\n","\n","prediction[\"ID\"] = index_list\n","prediction[\"label\"] = predicted_labels.detach().cpu().numpy()\n","\n","prediction = prediction.reset_index(drop=True)\n","\n","prediction.to_csv('20221119_하준서_sent_class.pred.csv', index = False)\n","\n","#index_list\n","prediction"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.0"}},"nbformat":4,"nbformat_minor":4}
